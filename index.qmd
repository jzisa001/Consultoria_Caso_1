---
title: "Caso 1 de Consultoría: Comparación de la talla estimada mediante ecuaciones de predicción en adultos mayores."
author:
  - name: "Ana Sofia Bello, Karol Ayala, Carlos Mario Castaño, Jesus Zisa"
    affiliation: "Departamento de estadística - Universidad Nacional de Colombia."
address:
  - Departamento de estadística - Universidad Nacional de Colombia.
format: 
  html:
    grid: 
      body-width: 1100px
      sidebar-width: 400px
      margin-width: 100px
      gutter-width:	1em
    toc-location: left
toc: true
echo: false
code-fold: true
code-summary: ""
warning: false
# embed-resources: true
---

```{r}
# Librerias 
library(readxl)
library(tidyverse)
library(nortest)
library(dplyr)
library(ggplot2)
library(GGally) # para la funcion ggpairs
library(gt)
library(gtExtras)
library(moments)
library(leaps)
library(MASS)
library(lmtest)
library(car)
library(BSDA) # Test del signo
library(glmnet)
library(glmtoolbox)
library(MASS)
```

## Lectura de datos
 
Se muestra a continuación la forma que tienen los datos.  
 
```{r}
# Lectura base de datos
datos <- read_excel("Datos/Corregida - COMPILADO DATOS COMUNIDAD DE CUIDADO Y CENTRO DÍA.xlsx", 
                      range = "B2:AN561", col_types = c("date", 
                      "skip", "text", "text", "text", "skip", 
                      "text", "numeric", "text", "skip", 
                      "skip", "skip", "skip", "numeric", 
                      "skip", "skip", "skip", "skip", "numeric", 
                      "skip", "skip", "skip", "skip", "numeric", 
                      "skip", "skip", "skip", "skip", "numeric", 
                      "skip", "skip", "skip", "skip", "numeric", 
                      "skip", "skip", "skip", "skip", "numeric"))
colnames(datos) <- c("Fecha", "Localidad", "Programa", "Unidad_atencion", 
                     "Sexo", "Edad", "Etnia", "Peso", "Talla",
                     "LRT_CM","LRT_A", "LRM_90","LRM_R")
datos$Sexo <- as.factor(datos$Sexo)
datos$Etnia <- as.factor(datos$Etnia)
datos <- datos[-which(datos$Edad<60),] # >60
datos <- datos |> as.data.frame()
head(datos) |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

## Análisis descriptivo

### Distribución, atípicos y test de normalidad

#### Sexo

```{r}
#| layout-ncol: 2

# summary(datos$Sexo)
# summary(datos$Sexo)/length(datos$Sexo)

datos_resumen <- datos %>%
  dplyr::count(Sexo) %>%
  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3))
datos_resumen |> gt() |> gtExtras::gt_theme_538()

ggplot(datos_resumen, aes(x = "", y = porcentaje, fill = Sexo)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  theme_void() +  # Elimina fondo y ejes
  labs(title = "Porcentaje de Hombres y Mujeres", fill = "Sexo") +
  geom_text(aes(label = paste0(round(porcentaje, 1), "%")),
            position = position_stack(vjust = 0.5), color = "white")
```

La muestra cuenta con 284 personas de sexo femenino y 275 masculino

#### Edad

Resumen de la variable `Edad`:

```{r}
summary(datos$Edad)
```

Distribución de la variable `Edad`

```{r}
#| layout-ncol: 2
hist(datos$Edad, freq=FALSE, main = 'Hstograma de Edad', xlab = 'Edad', ylab = 'Densidad')
lines(density(datos$Edad), col ="red")
box_Edad <- boxplot(datos$Edad)
```

Datos atípicos en la variable `Edad`:

```{r}
datos[which(datos$Edad>box_Edad$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> 
  tab_options(table.font.size = 9)
```

Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$Edad) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Edad, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$Edad) # No se tiene normalidad en la edad según el test de lillie
```

El mínimo de edad en la muestra es `r summary(datos$Edad)[1]` años, el máximo son `r max(datos$Edad)` años, la media es `r mean(datos$Edad)` años y la mediana es de`median(datos$Edad)` años. Existen dos datos atípicos: 93 y 95 años. 
No hay evidencia estadística de que la edad siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 4.496e-09, y el test Lilliefors muestra un p-valor de 1.168e-09. 


#### Etnia

Resumen de la variable `Etnia`:

```{r}
datos %>%
  dplyr::count(Etnia) %>%
  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3)) |> 
  gt() |> gtExtras::gt_theme_538()
# No se debería incluír un factor tan sesgado en el modelo
# Se puede tener en cuenta, sin embargo
```


#### Peso

Resumen de la variable `Peso`:

```{r}
summary(datos$Peso)
```

Distribución de la variable `Peso`:

```{r}
#| layout-ncol: 2
hist(datos$Peso, freq = FALSE, main = 'Histograma del peso', xlab = 'Peso', ylab = 'Densidad')
lines(density(datos$Peso), col = "red")
box_peso <- boxplot(datos$Peso)
```

Tenemos los siguientes datos atípicos en la variable `Peso`:

```{r}
datos[which(datos$Peso>box_peso$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distribución de la variable `Peso` distinguiendo por `Sexo`:

```{r}
box_peso_fm <- boxplot(datos$Peso ~ datos$Sexo, xlab = 'Sexo', ylab = 'Peso')
```

Datos atípicos cuando se distingue por `Sexo` en mujeres:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$Peso>box_peso_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Datos atípicos cuando se distingue por `Sexo` en hombres:

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$Peso>box_peso_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 8)
```
:::

En resúmen el mínimo de peso en la muestra es 34.20 kg, el máximo son 101.8 kg, la media son 63.34 kg y la mediana 62.8 kg. En la muestra junta, tenemos $8$ datos atípicos $101.80, 98.70, 97.65, 97.40, 97.10, 95.60, 95.10$ y $94.20$.  Cuando se separa por Sexo, tenemos $2$ datos atípicos en Femenino (97.10 y 91.6), y $4$ en Masculino (101.80, 98.70, 97.65 y 97.40). 


Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$Peso) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$Peso) # No se tiene normalidad en la edad según el test de Lilliefors
```

No hay evidencia estadística de que el peso siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 7.563e-05 y el test Lilliefors muestra un p-valor de 0.047304. 

#### Talla

Resumen de la variable `Talla`:

```{r}
summary(datos$Talla)
```

Distribución de la variable `Talla`:

```{r}
#| layout-ncol: 2
hist(datos$Talla, freq = FALSE, main = 'Histograma de Talla', xlab= 'Talla', ylab = 'Densidad')
lines(density(datos$Talla), col = "red")
box_talla <- boxplot(datos$Talla)
```

Tenemos un dato atípico en la variable `Talla`:

```{r}
datos[which(datos$Talla<box_talla$stats[1]|datos$Talla>box_talla$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distinguiendo por `Sexo`:

```{r}
box_talla_fm <- boxplot(datos$Talla ~ datos$Sexo, xlab='Sexo', ylab='Talla')
```

Datos atípicos cuando se distingue por `Sexo` en mujeres:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$Talla<box_talla_fm$stats[1,1]|(datos |> filter(Sexo == "Femenino"))$Talla>box_talla_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

En hombres: 

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$Talla<box_talla_fm$stats[1,2]|(datos |> filter(Sexo == "Masculino"))$Talla>box_talla_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```
:::

En resúmen, el mínimo de talla en la muestra es 127.1 cm, el máximo son 181.5 cm, la media son 155.95 cm y la mediana 155.15 cm. En la muestra junta, tenemos un dato atípico (127.1). Cuando se separa por Sexo, hay tres datos atípicos en Femenino (133.00, 133.85, 127.10, 129.25 y 132.55, 133.90) y en Masculino dos (142.00 y 141.50). 

Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$Talla) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$Talla) # No se tiene normalidad en la edad según el test de Lilliefors
```

El test Shapiro-Wilk arrojó un p-valor 0.05641 sugiriendo normalidad pero sin ser muy significativo, mientras que el test Lilliefors muestra un p-valor de 0.04836, por lo que no habría normalidad.



#### Longitud Rodilla Talón con cinta métrica `LRT_CM`

Resumen de la variable `LRT_CM`:

```{r}
summary(datos$LRT_CM)
```

Distribución de la variable `LRT_CM`:

```{r}
#| layout-ncol: 2
hist(datos$LRT_CM, freq = FALSE, main = 'Histograma de LRT medido con cinta métrica', xlab = 'Longitud en cm', ylab = 'Densidad')
lines(density(datos$LRT_CM), col = "red")
box_LRT_CM <- boxplot(datos$LRT_CM)
```

Datos atípicos:

```{r}
datos[which(datos$LRT_CM<box_LRT_CM$stats[1]|datos$LRT_CM>box_LRT_CM$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distribución de la variable `LRT_CM` distinguiendo por `Sexo`:

```{r}
box_LRT_CM_fm <- boxplot(datos$LRT_CM ~ datos$Sexo, xlab='Sexo', ylab='Longitud en cm')
```

Datos atípicos cuando se distingue por `Sexo` en mujeres:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$LRT_CM<box_LRT_CM_fm$stats[1,1]|(datos |> filter(Sexo == "Femenino"))$LRT_CM>box_LRT_CM_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Datos atípicos cuando se distingue por `Sexo` en hombres:

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$LRT_CM<box_LRT_CM_fm$stats[1,2]|(datos |> filter(Sexo == "Masculino"))$LRT_CM>box_LRT_CM_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```
:::

Pruebas de Normalidad:

En resúmen, el mínimo de LRT con cinta métrica en la muestra es 38 cm, el máximo son 59 cm, la media son 49 cm y la mediana 48.65 cm. En la muestra junta, parece haber tres datos atípicos (59, 39 y 38), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (39 y 38) y uno en Masculino (59). 

```{r}
#| layout-ncol: 2
shapiro.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Lilliefors
```

No hay evidencia estadística de que la LRT con cinta métrica siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.02391, y el test Lilliefors muestra un p-valor de 0.01056.

#### Longitud Rodilla Talón con Antropómetro `LRT_A`: 

Resumen de la variable `LRT_A`:

```{r}
summary(datos$LRT_A)
```

Distribución de la variable `LRT_A`:

```{r}
#| layout-ncol: 2
hist(datos$LRT_A, freq = FALSE, main ='Histograma de LRT con antropómetro', xlab = 'Longitud en cm', ylab = 'Densidad')
lines(density(datos$LRT_A), col = "red")
box_LRT_A <- boxplot(datos$LRT_A)
```

Datos atípicos en la variable `LRT_A`:

```{r}
datos[which(datos$LRT_A<box_LRT_A$stats[1]|datos$LRT_A>box_LRT_A$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distribución de la variable `LRT_A` distinguiendo por `Sexo`:

```{r}
box_LRT_A_fm <- boxplot(datos$LRT_A ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRT con antropómetro en cm')
```


Datos atípicos cuando se distingue por `Sexo` en mujeres:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$LRT_A<box_LRT_A_fm$stats[1,1]|(datos |> filter(Sexo == "Femenino"))$LRT_A>box_LRT_A_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Datos atípicos cuando se distingue por `Sexo` en hombres:

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$LRT_A<box_LRT_A_fm$stats[1,2]|(datos |> filter(Sexo == "Masculino"))$LRT_A>box_LRT_A_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```
:::

En resúmen, el mínimo de LRT con antropómetro en la muestra es 36.85 cm, el máximo son 58.35 cm, la media son 47.54 cm y la mediana 47.4 cm. En la muestra junta, tenemos 3 datos atípicos (58.35, 37.00 y 36.85). Cuando se separa por Sexo, parece haber tres datos atípicos en Femenino (37.00, 36.85 y 38.20) y en Masculino dos (57.65 y 58.35).

Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Lilliefors
```

No hay evidencia estadística de que la LRT con antropómetro siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.0507 (no es muy significativo), y el test Lilliefors muestra un p-valor de 0.01345. 

#### Longitud Rodilla-Maléolo a 90° `LRM_90`

Resumen de la variable `LRM_90`:

```{r}
summary(datos$LRM_90)
```

Distribución de la variable `LRM_90`:

```{r}
#| layout-ncol: 2
hist(datos$LRM_90, freq = FALSE, main = 'Histograma de LRM a 90°', xlab = 'Longitud en cm', ylab = 'Densidad')
lines(density(datos$LRM_90), col = "red")
box_LRM_90<- boxplot(datos$LRM_90)
```

Datos atípicos en la variable `LRM_90`:

```{r}
datos[which(datos$LRM_90<box_LRM_90$stats[1]|datos$LRM_90>box_LRM_90$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distribución de la variable `LRM_90` distinguiendo por `Sexo`:

```{r}
box_LRM_90_fm <- boxplot(datos$LRM_90 ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM a 90° en cm')
```


Datos atípicos en mujeres cuando se distingue por `Sexo`:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$LRM_90<box_LRM_90_fm$stats[1,1]|(datos |> filter(Sexo == "Femenino"))$LRM_90>box_LRM_90_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Datos atípicos en hombres cuando se distingue por `Sexo`:

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$LRM_90<box_LRM_90_fm$stats[1,2]|(datos |> filter(Sexo == "Masculino"))$LRM_90>box_LRM_90_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```
:::

El mínimo de LRM con la pierna a 90° en la muestra es 31.85 cm, el máximo son 54.65 cm, la media son 43.33 cm y la mediana 43.2 cm. En la muestra junta, tenemos 6 datos atípicos (53.00, 54.65, 52.30, 52.30, 34.00, 31.85). Cuando se separa por Sexo, tenemos 2 datos atípicos en Femenino (34.00 y 31.85), y en Masculino 2 (53.00, 54.65).

Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Lilliefors
```

Con el test Shapiro-Wilk no tenemos normalidad en distribución pues tenemos un p-valor de 0.01393, mientras que el test Lilliefors muestra un p-valor de 0.001307, por lo que no habría normalidad.

#### Longitud Rodilla-Maléolo la pierna totalmente estirada `LRM_R`

Resumen de la variable `LRM_R`:

```{r}
summary(datos$LRM_R)
```

Distribución de la variable `LRM_R`:

```{r}
#| layout-ncol: 2
hist(datos$LRM_R, freq = FALSE, main = 'Histograma de LRM recta', xlab = 'Longitud en cm', ylab='Densidad')
lines(density(datos$LRM_R), col = "red")
box_LRM_R<- boxplot(datos$LRM_R)
```

Datos atípicos en la variable `LRM_R`:

```{r}
datos[which(datos$LRM_R<box_LRM_R$stats[1]|datos$LRM_R>box_LRM_R$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Distribución de la variable `LRM_R` distinguiendo por `Sexo`:

```{r}
box_LRM_R_fm <- boxplot(datos$LRM_R ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM recta en cm')
```


Datos atípicos en mujeres cuando se distingue por `Sexo`:

::: {layout-nrow="2"}

```{r}
(datos |> filter(Sexo == "Femenino"))[which((datos |> filter(Sexo == "Femenino"))$LRM_R<box_LRM_R_fm$stats[1,1]|(datos |> filter(Sexo == "Femenino"))$LRM_R>box_LRM_R_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```

Datos atípicos en hombres cuando se distingue por `Sexo`:

```{r}
(datos |> filter(Sexo == "Masculino"))[which((datos |> filter(Sexo == "Masculino"))$LRM_R<box_LRM_R_fm$stats[1,2]|(datos |> filter(Sexo == "Masculino"))$LRM_R>box_LRM_R_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
```
:::

El mínimo de LRM con la pierna recta en la muestra es 31.45 cm, el máximo son 52.5 cm, la media son 42.54 cm y la mediana 42.50 cm. En la muestra junta, parece haber un dato atípico (31.45), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (33.50 y 31.45), y en Masculino cuatro (52.50, 51.35, 52.50, 51.25, 37.70 y 37.75).

Pruebas de Normalidad:

```{r}
#| layout-ncol: 2
shapiro.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov
lillie.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Lilliefors
```

Con el test Shapiro-Wilk parece haber normalidad pues tenemos un p-valor de 0.09192, mientras que el test Lilliefors muestra un p-valor de 0.004743, por lo que no habría normalidad.

### Análisis de correlación

```{r}
ggpairs(
  datos[,-c(1:5, 7)],  # Tu subconjunto de datos
  lower = list(continuous = wrap("smooth", method = "lm", color = "lightblue")),  # Línea de regresión en rojo
  title = "Matriz de correlaciones"
)
```

Existe una fuerte correlación lineal positiva entre la variable talla y cada una de las mediciones de la longitud rodilla-talón y rodilla-maléolo, considerarlas para los diferentes modelos de regresión parece ser una buena opción. La talla está correlacionada con el peso de forma moderada, por lo que valdría la pena explorar su contribución en los modelos propuestos. No parece haber una correlación lineal significativa entre la talla y la edad, sugiriendo que no sería necesario incluir la edad en los modelos propuestos.

En principio, dado que la relación entre cada una de las medidas de la longitud rodilla-talón y rodilla-maléolo presentan una relación lineal fuerte con la talla, se podría pensar que la que tenga una mayor correlación con la talla, es la que daría mejores estimaciones de la talla real. En este caso, la longitud rodilla-talón con antropómetro, es la que presenta una mayor correlación con la talla, por lo que posiblemente sea más preciso usar esta medida para estimar la talla real de los adultos mayores. Como sabemos, el antropómetro es una herramienta que no siempre es de fácil acceso y justamente queremos evaluar si existen diferencias significativas entre usar esta medición y las demás mediciones que sí son de fácil acceso y aplicación.

En ese orden de ideas, después de la longitud de rodilla talón con antropómetro, la longitud rodilla-talón con cinta métrica es la variable que tiene más correlación con la talla, luego sigue la longitud rodilla-maléolo con la pierna totalmente estirada y por último la longitud rodilla-maléolo con la pierna a 90 grados.

## Hipótesis

### Longitud rodilla-talón

Inicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:

```{r}
# Comparar LRT CM y A
boxplot(data.frame(datos$LRT_CM, datos$LRT_A))
```

Según el gráfico de cajas (boxplot), parece que hay una pequeña diferencia entre las mediciones de la longitud desde la rodilla hasta el talón realizadas con cinta métrica y con antropómetro. Sin embargo, para estar seguros, es necesario hacer una prueba estadística más formal. Para esto, se calculan las diferencias entre las mediciones de ambos métodos y se verifica si esas diferencias siguen una distribución normal. Dependiendo del resultado, se elegirá la prueba estadística adecuada para comprobar si realmente no hay una diferencia significativa entre ambos tipos de medición.

```{r}
# Diferencias CM y A
LRT_dif <- datos$LRT_CM - datos$LRT_A

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
```
Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro sigan una distribución normal. Por lo tanto, es necesario usar un tipo de prueba estadística diferente, que no dependa de suposiciones sobre la distribución de los datos, para analizar las diferencias en los promedios.

```{r}
#| eval: false
#| echo: false
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon 

# wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
```

```{r}
# Prueba del signo para muestras pareadas
## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)

SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
```

Al principio, se pensó en usar la prueba de Wilcoxon, que es una prueba estadística no paramétrica para evaluar el promedio de las diferencias. Sin embargo, esta prueba asume que las diferencias entre las mediciones son simétricas, pero eso no ocurrió en nuestros datos, ya que el coeficiente de asimetría fue de -0.785, lo que muestra que las diferencias no son simétricas. Por eso, se decidió usar una prueba diferente llamada "prueba del signo para muestras pareadas", que no necesita asumir normalidad ni simetría. Aunque esta prueba no da información sobre el promedio de las diferencias, sí permite evaluar la mediana de las diferencias.

El resultado de la prueba del signo mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro.

#### Análisis por separado

##### Por sexo
###### Masculino:

```{r}
# Diferencias CM y A
hombres <- datos[datos$Sexo == "Masculino",]
LRT_dif <- hombres$LRT_CM - hombres$LRT_A

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors

```
Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de sexo masculino sigan una distribución normal. 
```{r}
#| eval: false
#| echo: false
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon 

# wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos

```

```{r}
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
```
Al principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.69. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.

El resultado de la prueba del signo mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores de sexo masculino.

###### Femenino:
```{r}
# Diferencias CM y A
mujeres <- datos[datos$Sexo == "Femenino",]
LRT_dif <- mujeres$LRT_CM - mujeres$LRT_A

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors

```
Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en las mujeres mayores sigan una distribución normal. 

```{r}
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon 

```
Probrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.
```{r}

wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
```
El resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en las mujeres mayores.

##### Por programa

###### Centro día:
```{r}
# Diferencias CM y A
cd <- datos[datos$Programa == "Centro Día Casa de la Sabiduría",]
LRT_dif <- cd$LRT_CM - cd$LRT_A

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
```

Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores del centro día sigan una distribución normal. 

```{r}
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon 

```
Probrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.

```{r}

wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
```
El resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores del centro día.

###### Comunidad de cuidado
```{r}
# Diferencias CM y A
cc <- datos[datos$Programa == "Comunidad de Cuidado",]
LRT_dif <- cc$LRT_CM - cc$LRT_A

hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
```
Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de las comunidades de cuidado sigan una distribución normal. 

```{r}
#| eval: false
#| echo: false
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que no hay simetria, entonces no se aplica Wilcoxon 
```

```{r}
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
```
Al principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.64. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.

El resultado de la prueba del signo mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro,  en los adultos mayores de las comunidades de cuidado.

##### Por etnia

###### Blanco-Mestizo
```{r}
# Diferencias CM y A 
bm <- datos[datos$Etnia=="Blanco-Mestizo",]
LRT_dif <- bm$LRT_CM - bm$LRT_A

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
```
Los resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores Blancos-Mestizos sigan una distribución normal. 
```{r}
#| eval: false
#| echo: false
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que no hay simetria, entonces no se aplica Wilcoxon 
```

```{r}
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
```
Al principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -0.78. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.

El resultado de la prueba del signo mostró un p-valor de $2.2 \times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores Blancos-Mestizos.

###### Afrocolombiano, indigenas, Rrom 

```{r}
# Diferencias CM y A 
nobm <- datos[datos$Etnia!="Blanco-Mestizo",]
LRT_dif <- nobm$LRT_CM - nobm$LRT_A
#length(LRT_dif)

# Como se ve graficamente, parece que no hay normalidad
hist(LRT_dif)
boxplot(LRT_dif) # No hay outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # Se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRT_dif) # Se tiene normalidad según el test de Lilliefors
```
Uno de los resultados de las pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostró un valor menor a 0.05 y la otra un valor mayor. Dado que de estas etnias solo hay 12 adultos mayores, las pruebas son más sensibles y pueden dar resultados menos confiables. Por esa razón, se va a evaluar la simetría de las diferencias para no realizar la prueba que asume normalidad.

```{r}
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRT_dif)

t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon 

```
Probrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.

```{r}

wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
```
El resultado de la prueba de Wilcoxon mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Sin embargo, la prueba no puede calcular el p-valor exacto debido a la presencia de valores repetidos en las diferencias, por lo que se va a realizar el test del signo.
```{r}
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
```
El resultado de la prueba del signo mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores afrocolombiano, indigenas o Rrom.


### Longitud rodilla-maléolo

Inicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:

```{r}
# Comparar LRM 90 y R
boxplot(data.frame(datos$LRM_90, datos$LRM_R))
```

Según el boxplot, se puede observar que sí existe una leve diferencia entre las distribuciones de las mediciones de la longitud rodilla maléolo con la pierna a 90° y con la pierna completamente estirada. Sin embargo, es necesario, realizar una prueba estadística formal para concluir algo, por lo que se calculan las diferencias entre ambos métodos y se les aplica un test de normalidad para elegir qué prueba utilizar para evaluar la hipótesis nula de que la medición longitud rodilla-maléolo con la pierna completamente estirada es igual a la medición de la longitud rodilla-maléolo con la pierna a $90°$.

```{r}
# Diferencias CM y A
LRM_dif <- datos$LRM_90 - datos$LRM_R

# Como se ve graficamente, parece que no hay normalidad
hist(LRM_dif)
boxplot(LRM_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRM_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(LRM_dif) # No se tiene normalidad en la edad según el test de Lilliefors
```

Dado que en ambos test, Shapiro-Wilk y Lilliefors, se obtuvo un p-valor menor a $0.05$, entonces, con una significancia del $5\%$, no hay evidencia estadística de que las diferencias entre las mediciones rodilla-talón con cinta métrica y con antropómetro sigan una distribució normal. Por lo tanto, se hace necesario realizar un test no paramétrico para media de las diferencias.

```{r}
#| eval: false
#| echo: false
# Test Wilcoxon

## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos

asimetria <- moments::skewness(LRM_dif)

t_test <- asimetria / sqrt(6 / length(LRM_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRM_dif) - 1))
p_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon 

# wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
```

```{r}
# Prueba del signo para muestras pareadas
## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)

SIGN.test(LRM_dif, md = 0, alternative = "two.sided")
```

Nuevamente, se consideró aplicar la prueba de Wilcoxon para evaluar la media de las diferencias, pero esta prueba no se aplicó ya que el coeficiente de asimetría obtenido fue de $2.022$. Este valor indica una falta de simetría en las diferencias de las mediciones. Por esta razón, de nuevo se optó por utilizar la prueba del signo para muestras pareadas.

El resultado de la prueba del signo arrojó un p-valor de $2.2 \times 10^{-16}$, indicando evidencia estadística suficiente para rechazar la hipótesis nula de que la mediana de las diferencias es igual a cero. Por lo tanto, se concluye que las mediciones de la longitud rodilla-maléolo realizadas con la pierna completamente estirada no son equivalentes a las obtenidas con la pierna a $90°$.

### Talla real y estimación Benjumea (LRT) con cinta métrica

Primero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con cinta métrica. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es "Rrom", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.

```{r}
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$benjumea_cm <- ifelse(
  datos$Sexo == "Masculino" & datos$Etnia == "Blanco-Mestizo",
  75.514 + 1.883 * datos$LRT_CM - 0.108 * datos$Edad,
  ifelse(
    datos$Sexo == "Femenino" & datos$Etnia == "Blanco-Mestizo",
    86.497 + 1.553 * datos$LRT_CM - 0.119 * datos$Edad,
    ifelse(
      datos$Sexo == "Masculino" & datos$Etnia == "Indigena",
      82.695 + 1.745 * datos$LRT_CM - 0.121 * datos$Edad,
      ifelse(
        datos$Sexo == "Femenino" & datos$Etnia == "Indigena",
        90.281 + 1.436 * datos$LRT_CM - 0.102 * datos$Edad,
        ifelse(
          datos$Sexo == "Masculino" & datos$Etnia == "Afrocolombiano",
          79.298 + 1.855 * datos$LRT_CM - 0.141 * datos$Edad,
          ifelse(
            datos$Sexo == "Femenino" & datos$Etnia == "Afrocolombiano",
            76.233 + 1.767 * datos$LRT_CM - 0.098 * datos$Edad,
            NA # solo hay un NA que es el Rrom
          )
        )
      )
    )
  )
)
```

Como antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con cinta métrica y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.

```{r}
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$benjumea_cm))
```

Se calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con cinta métrica, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.

```{r}
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$benjumea_cm
talla_dif <- talla_dif[!is.na(talla_dif)]

# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
```

En ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.

```{r}
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)

t.test(talla_dif, alternative = "two.sided", mu = 0)
```

Luego de aplicar la prueba $t$, con una significancia del $5\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con cinta métrica no es cero, luego, parece que las estimaciones no son cercanas a la talla real.

El MSE del modelo de Benjumea sobre nuestros datos es el siguiente:

```{r}
mean((datos$Talla - datos$benjumea_cm)^2, na.rm = TRUE)
```

#### Sin los outliers

```{r}
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out

talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]


# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif1)

# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
```

También da que la diferencia no es cero.

### Talla real y estimación Benjumea (LRT) con antropómetro

Primero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con antropómetro. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es "Rrom", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.

```{r}
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$benjumea_a <- ifelse(
  datos$Sexo == "Masculino" & datos$Etnia == "Blanco-Mestizo",
  75.514 + 1.883 * datos$LRT_A - 0.108 * datos$Edad,
  ifelse(
    datos$Sexo == "Femenino" & datos$Etnia == "Blanco-Mestizo",
    86.497 + 1.553 * datos$LRT_A - 0.119 * datos$Edad,
    ifelse(
      datos$Sexo == "Masculino" & datos$Etnia == "Indigena",
      82.695 + 1.745 * datos$LRT_A - 0.121 * datos$Edad,
      ifelse(
        datos$Sexo == "Femenino" & datos$Etnia == "Indigena",
        90.281 + 1.436 * datos$LRT_A - 0.102 * datos$Edad,
        ifelse(
          datos$Sexo == "Masculino" & datos$Etnia == "Afrocolombiano",
          79.298 + 1.855 * datos$LRT_A - 0.141 * datos$Edad,
          ifelse(
            datos$Sexo == "Femenino" & datos$Etnia == "Afrocolombiano",
            76.233 + 1.767 * datos$LRT_A - 0.098 * datos$Edad,
            NA # solo hay un NA que es el Rrom
          )
        )
      )
    )
  )
)
```

Como antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con antropómetro y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.

```{r}
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$benjumea_a))
```

Se calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con antropómetro, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.

```{r}
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$benjumea_a
talla_dif <- talla_dif[!is.na(talla_dif)]

# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
```

En ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.

```{r}
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)

t.test(talla_dif, alternative = "two.sided", mu = 0)
```

Luego de aplicar la prueba $t$, con una significancia del $5\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $4.103 \times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con antropómetro no es cero, luego, parece que las estimaciones no son cercanas a la talla real.

El MSE del modelo de Benjumea sobre nuestros datos es el siguiente:

```{r}
mean((datos$Talla - datos$benjumea_a)^2, na.rm = TRUE)
```

#### Sin los outliers

```{r}
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out

talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]


# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif1)

# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
```

También da que la diferencia no es cero.

### Talla real y estimación Arango Zamor (LRM) a $90°$

Primero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo a $90°$.

```{r}
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$arango_90 <- ifelse(
  datos$Sexo == "Masculino",
  119.6 + 1.121*datos$LRM_90 - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_90 - 0.159*datos$Edad)
```

Como antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$ y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.

```{r}
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$arango_90))
```

Se calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.

```{r}
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$arango_90

# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
```

En ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.

```{r}
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)

t.test(talla_dif, alternative = "two.sided", mu = 0)
```

Luego de aplicar la prueba $t$, con una significancia del $5\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $9.685 \times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna a $90°$ no es cero, luego, parece que las estimaciones no son cercanas a la talla real.

El MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:

```{r}
mean((datos$Talla - datos$arango_90)^2, na.rm = TRUE)
```

#### Sin los outliers

```{r}
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out

talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]


# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif1)

# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
```

También da que la diferencia no es cero.

### Talla real y estimación Arango Zamor (LRM) con la pierna estirada

Primero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo con la pierna estirada.

```{r}
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$arango_r <- ifelse(
  datos$Sexo == "Masculino",
  119.6 + 1.121*datos$LRM_R - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_R - 0.159*datos$Edad)
```

Como antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna estirada y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.

```{r}
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$arango_r))
```

Se calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a estirada, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.

```{r}
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$arango_r

# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers

# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks

## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
```

En ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.

```{r}
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)

t.test(talla_dif, alternative = "two.sided", mu = 0)
```

Luego de aplicar la prueba $t$, con una significancia del $5\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna estirada no es cero, luego, parece que las estimaciones no son cercanas a la talla real.

El MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:

```{r}
mean((datos$Talla - datos$arango_r)^2, na.rm = TRUE)
```

## Modelos

A continuación el resumen de la evaluación de las hipótesis de interés:

-   La diferencia en las mediciones de LRT con antropómetro y con cinta métrica resultó ser estadísticamente significativa.
-   La diferencia en las mediciones de LRM con la pierna a $90°$ y la pierna estirada resultó ser estadísticamente significativa.

Estos resultados sigieren que:

-   No es posible determinar que las mediciones de LRT con la cinta métrica sean iguales a las obtenidad con antropómetro. Asumiendo que la medición con antropómetro es más exacta, las mediciones con la cinta métrica suelen sobreestimar en promedio a las del antropómetro.
-   Tampoco es posible determinar que las mediciones de LRM con la pierna a $90°$ y con la pierna estirada sean iguales. La medición con la pierna estirada suele ser en promedio menor a la medición hecha con la pierna a $90°$.

Los resultados obtenidos al evaluar las fórmulas de ***Benjumea*** y de ***Arango y Zamora*** en mustra de adultos mayores que atiende la SDIS, parecen no tener muy buenos resultados a la hora de estimar la talla de los adultos mayores.

Dado estos resultados, se concluye que se requiere de fórmulas específicas para la población que atiende la **SDIS**. Además, se deberá ajustar estos modelos para las cuatro mediciones pues la evaluación de las hipótesis no dieron indicios de la igualdad entre los métodos de las mediciones.

### Selección del mejor modelo usando LRT_A

Inicialmente, se hará la selección del mejor modelo para LRT_A mediante un enfoque predictivo.

A continuación se hace una búsqueda del mejor modelo por cada número de posibles combinaciones de variables. Primero se hará la búsqueda usando todo el conjunto de datos.

```{r}
regfit.full <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa,
                          datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables 

(reg.summary <- summary(regfit.full))
# names(reg.summary)
```

$R^2$, $R^2$ ajustado, SCE, y BIC para cada mejor modelo del correspondiente tamaño:

```{r}
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
```

Usando el criterio BIC, el mejor modelo es el de 3 variables:

```{r}
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
```

Usando el $R^2$ ajustado, se sugiere un modelo con 5 variables:

```{r}
plot(regfit.full , scale = "adjr2")
```

Los coeficientes del mejor modelo usando el criterio de BIC son:

```{r}
coef(regfit.full, 3)
```

Esto sugiere usar el modelo $Talla = 58.67 + 2.19 LRT\_A - 0.12Edad + 3.06Sexo$,\
$$Sexo = \begin{cases} 1 & \text{si sexo = hombre} \\ 0 & \text{si sexo = mujer} \end{cases}$$

Ahora se hará la búsqueda del mejor modelo usando ***K - fold cross validation*** con el fin de calcular directamente los errores de predicción sobre los datos de testeo y evitar así el sobreajuste.

-   Se crean ***K - folds*** (pliegues) de aproximadamente igual tamaño. En este caso fijamos $k = 10$. Como tenemos $558$ datos, cada pliegue será de tamaño 55 o 56.
-   El $k-ésimo$ pliegue servirá para testear, y los demás pliegues se juntan para entrenar los modelos. Osea que se usará un $90\%$ de los datos para entrenamiento y $10\%$ para test.
-   Para $k = 1,\cdots,10,$ se hace la búsqueda del mejor modelo para cada número de variables y se calcula el MSE.
-   Luego, se promedia el MSE a través de los $10$ pliegues y se escoge el tamaño de modelo con menor MSE promedio.
-   Finalmente, se hace la búsqueda del mejor modelo por cada número de variables usando todos los datos disponibles y se escoge el modelo asociado al tamaño del modelo obtenido en la validación cruzada.

Tamaño de los pliegues:

```{r}
k <- 10 # k-folds
n <- nrow(datos)
set.seed(123)
folds <- sample(rep(1:k, length = n))
table(folds) # tamaño de cada k-fold
cv.errors <- matrix(NA, k, 7, dimnames = list(NULL , paste (1:7))) # Matriz para almacenar los errores
```

MSE promedio a través de los $10$ pliegues para cada número de variables incluídas en el modelo:

```{r}
# Función para hacer la predicción de los datos de test en cada k-fold
predict.regsubsets <- function(object , newdata , id, ...) {
  form <- as.formula(object$call [[2]])
  mat <- model.matrix(form , newdata)
  coefi <- coef(object , id = id)
  xvars <- names(coefi)
  mat[, xvars] %*% coefi
}

for (j in 1:k) {
  best.fit <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos[folds != j, ], nvmax = 10)
  for (i in 1:7) { # Se usa 8 porque los modelos tienen un tamaño máximo de 8 variables en el regsubsets
  pred <- predict(best.fit , datos[folds == j, ], id = i)
  cv.errors[j, i] <- mean((datos$Talla[folds == j] - pred)^2)
  }
}
# Hay un pequeño problema de multicolinealidad (parece que sucede cuando se incluye la etnia)
# por eso en vez del 8 puse 7 (porque generaba un error por multicolinealidad)

mean.cv.errors <- apply(cv.errors , 2, mean, na.rm = TRUE)
mean.cv.errors # El menor MSE promedio es cuando se usa un modelo con 3 variables
```

El MSE se minimiza usando un modelo de 3 variables:

```{r}
par(mfrow = c(1, 1))
plot(mean.cv.errors , type = "b")
```

Se busca nuevamente el mejor modelo de tres variables usando todos los datos:

```{r}
# Se busca nuevamente el mejor modelo de 3 variables
reg.best <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos, nvmax = 10)
regbest.summary <- summary(reg.best)
regbest.summary$bic

coef(reg.best, 3)
```

Casualmente volvió a dar el mismo modelo con tres variables que incluye LRT_A, la Edad y el Sexo. Esto es seguramente porque las demás variables no contribuyen significativamente a la presición predictiva de los modelos.

Ahora se validarán los supuestos para el mejor modelo obtenido:

```{r}
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
```

El modelo tiene un $R^2$ ajustado de $0.8861$, es decir que aproximadamente un $88.61\%$ de la variabilidad de la talla es explicada por LRT_A, la edad y el sexo. 

***Linealidad:*** Con el fin de verificar que la relación entre la talla y las variables LRT_A (discriminando por sexo) y la edad es lineal, se visualiza el gráfico de los residuos vs los valores predichos del modelo $\left(\hat{e},\hat{y} \right)$:

```{r}
plot(reg, which = 1)
```

El gráfico no muestra ningún patrón marcado, la ubicación de los puntos parece ser aleatoria alrededor de cero, indicando también homoscedasticidad en los residuales y posible independencia de los mismos. El gráfico muestra algunos valores atípicos que valdría la pena explorar.

***Independencia de los errores:*** Aunque nuestros datos no son temporales, el test de Durbin-Watson nos puede ayudar a evaluar la autocorrelación de los errores del modelo:

```{r}
dwtest(reg)
```

La estadística del test de Durbin-Watson es muy cercano a $2$, se concluye que los errores son independientes.

***Normalidad de los errores:*** Se realiza el gráfico QQ-plot para comparar la distribución de los residuales del modelo con la distribución teórica de una normal. También se hace el test de normalidad de Lilliefors y Anderson-Darling:

```{r}
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
```

El QQ-plot muestra que los residuales se ajustan aceptablemente a una distribución normal. Las pruebas de normalidad de Lilliefors y Anderson-Darling también apoyan este resultado.

***Homoscedasticidad:*** Aunque no se vio un patron que indicara heteroscedasticidad en el gráfico de los residuales vs los valores predichos, a continuación se muestra el gráfico de los residuales estandarizados vs los valores predichos con el fin de mejorar la interpretabilidad de la homoscedasticidad y tener una visión más clara de las observaciones atípicas e influyentes:

```{r}
plot(reg, which = 3)
```

No se observan patrones que indiquen hereroscedasticidad en los residuos (forma de cono o embudo). Se siguien observando algunas observaciones atípicas y/o influyentes.

Adicional, se realiza la prueba de Breusch-Pagan para verificar la homoscedasticidad de los residuales:

```{r}
bptest(reg)
```

No se rechaza la hipótesis nula de que los errores del modelo son homoscedasticos.

***Multicolinealidad:*** Se verifica que las variables incluídas en el modelo no están altamente correlacionadas entre sí, y así evitar obtener resultados inestables que dificulten la interpretabilidad de los coeficientes del modelo. Se calculan los Factores de Inflación de la Varianza (VIFs):

```{r}
vif(reg)
```

Dado que los VIFs son mucho menores a 5, esto indica que cada variable tiene una correlación moderada (leve) con las demás. Por lo que se puede concluir que los resultados del modelo posiblemente no estarán muy afectados por la multicolinealidad.

***El modelo está bien especificado:*** Se hace el test de RESET para examinar si el modelo ajustado está bien especificado o si se han omitido términos no lineales o interacciones importantes:

```{r}
resettest(reg, type="regressor")
resettest(reg, type="fitted")
```

No se rechaza la hipótesis nula de que el modelo está bien especificado.

***Obervaciones atípicas y de alto apalancamiento:*** 

```{r}
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
```

Usando los residuales estudentizados, se observan $5$ datos atípicos.

```{r}
#| layout-ncol: 2
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]

influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
```

En total 29 observaciones superan el umbral especificado para la distancia de Cook, pero esto no significa que todas sean influyentes (alto leverage). Particularmente hay 3 observaciones que son marcadas como influyentes significativamente según la distancia de Cook. Esto indica que la inclusión de estas observaciones en el modelo pueden tener una influencia significativa en los coeficientes del modelo y en la predicción de la talla. Se debe explorar con cautela estas observaciones y decidir qué hacer con ellas.

Para esto, se puede comprobar el cambio en los coeficientes del modelo al excluir estas observaciones influyentes.

```{r}
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})
summary(reg2)
```

Las estimaciones de los coeficientes del modelo sin las obervaciones influyentes han cambiado un poco respecto al modelo original. El $R^2$ ajustado ha incrementado un poco también.

### Modelo Lasso

En este modelo se incluirán las cuatro mediciones, con el fin de escoger la mejor. Se espera que el modelo sea capaz de inducir escacez en los coeficientes del modelo, especialmente a los correspondientes a las mediciones LRT_A, LRT_CM, LRM_90 y LRM_R, de tal manera que pueda escoger la medición que al momento de estimar la talla sea más precisa.

Se particionan los datos en entrenamiento y prueba,

```{r}
x <- model.matrix(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]
y <- datos$Talla

grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE

set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
```

Algunos coeficientes se hacen cero:
  
```{r}
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
```

Se hace ***k-fold cross validation*** con $k = 10$ y se promedia el MSE:
  
```{r}
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba 

out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:12, ]
```

Los coeficientes del modelo resultante son:
  
```{r}
lasso.coef
```

y los coeficientes distintos de cero:
  
```{r}
lasso.coef[lasso.coef != 0]
```

Se observa que algunos coeficientes se hicieron cero, incluyendo el de LRM_90. Pero aún así el modelo todavía incluye LRT_A, LRT_CM y LRM_R al tiempo. Esto puede ser debido a que cada una de las mediciones está muy correlacionada con la talla y que además están muy correlacionadas entre ellas. Se observa que LRT_A tiene un coeficiente mucho mayor que LRT_CM y LRM_R haciendo ver que el modelo las trató de llevar a cero pero no por completo.

El MSE de este modelo sobre los datos de prueba fue de $8.92$. Se puede probar aumentar el valor de $\lambda$ (sumando pequeñas cantidades al $\lambda$ que minimizó el MSE en la validación cruzada), resultará un modelo más sencillo a la vez que aumenta el MSE sobre los datos de prueba.

### Lasso sin tener en cuenta LRT_A

Ya que la idea es estimar la altura de los adultos mayores usando alguno de los métodos más sencillos y accecibles para quienes toman las medidas, se excluye en este modelo LRT_A ya que es de difícil acceso y poco económico.

Se ajusta el modelo Lasso con las tres mediciones LRT_CM, LRM_90 y LRM_R.

```{r}
x <- model.matrix(Talla ~ LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]
y <- datos$Talla

grid <- 10^seq(10, -2, length = 100)

set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9)
test <- (-train)
y.test <- y[test]

lasso.mod <- glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
# plot(lasso.mod)

set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2)

out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:11, ]

lasso.coef

lasso.coef[lasso.coef != 0]
```

El modelo sugiere incluir al tiempo LRT_CM y LRM_R. Para este modelo el MSE sobre el conjunto de test fue de $10.30$. 

Se ajusta el valor de $\lambda$ con el fin de llevar a cero algunos coeficientes adicionales:
  
```{r}
bestlam <- cv.out$lambda.min + 0.1
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2)

out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:11, ]

lasso.coef

lasso.coef[lasso.coef != 0]
```

Se obtiene un modelo más sencillo con un MSE de $10.37$.

### Modelo Gamma

```{r}



# StepCriterion

#sc <- stepCriterion(gamma.reg, direction="backward", criterion="aic", test="wald")

# Ajuste con stepAIC, guardando resultados intermedios

# Forward
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)

gamma.reg <- glm(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Etnia + Peso + Sexo + Programa, family= Gamma(),data = datos)
summary(gamma.reg)

stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC

modelos_intermedios <- list()

# Función para guardar modelos en cada paso
guardar_modelos <- function(object, ...) {
  modelos_intermedios[[length(modelos_intermedios) + 1]] <<- object
  FALSE  # Devuelve FALSE para continuar con el proceso
}

# Selección hacia adelante con BIC y almacenamiento de modelos intermedios
stepwise <- stepAIC(
  gamma.reg_null,
  scope = list(lower = gamma.reg_null, upper = gamma.reg),
  direction = "forward",
  trace = TRUE,
  k = log(nrow(datos)),  # Usar BIC en lugar de AIC
  keep = guardar_modelos  # Guardar cada modelo intermedio
)


forms_gamma <- lapply(modelos_intermedios, formula)
#forms_gamma


#kfolds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL

k = 10
for (j in 1:k) {
  best.fit <- lapply(forms_gamma, function(formula){
    glm(formula, family = Gamma(), data = datos[folds != j, ])
})
  #for (i in 1:length(forms_gamma)) {
    pred <- lapply(best.fit, function(model){
      predict(model, datos[folds == j, ], type = "response")
      })
    cv.errors <- lapply(pred, function(coefs){
       mean((datos$Talla[folds == j] - coefs)^2)
    })
    cv.errors <- as.data.frame(cv.errors)
    colnames(cv.errors) <- c(paste("Mod", 1:length(forms_gamma)))
    CV.ERRORS <- rbind(CV.ERRORS, cv.errors)
  #}
}

# Error cuadratico medio
mean.cv.errors <- apply(CV.ERRORS , 2, mean, na.rm = TRUE)
mean.cv.errors 


```

