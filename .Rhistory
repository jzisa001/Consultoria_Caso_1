# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_R + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 20
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_R", MSE = mean(errores))) # No se incluye pq aparentemente hay una leve homocedasticidad en los errores
# Chunk 21
#| results: hide
regfit.full <- regsubsets(Talla ~ LRM_90 + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
# Chunk 22
reg.summary$bic
# Chunk 23
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Chunk 24
coef(regfit.full, 3)
# Chunk 25
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_90 + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 26
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_90", MSE = mean(errores))) # No se incluye pq el modelo no está bien especificado
# Chunk 27
MSEs[1:4,]
# Chunk 28
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
# Chunk 29
plot(reg, which = 1)
# Chunk 30
dwtest(reg)
# Chunk 31
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
# Chunk 32
plot(reg, which = 3)
# Chunk 33
bptest(reg)
# Chunk 34
vif(reg)
# Chunk 35
resettest(reg, type="regressor")
resettest(reg, type="fitted")
# Chunk 36
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
# Chunk 37
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
# Chunk 38
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})
summary(reg2)
datos2 <- datos %>% # dataframe auxiliar para obener los id de los k-folds
mutate(index = row_number())
# Se crean los k-fols igual que en el modelo normal
set.seed(123)
folds <- vfold_cv(datos2, v = 10)
fold_id <- rep(0, nrow(datos2)) # id's de los k-folds
for(i in 1:10){
prueba = assessment(folds$splits[[i]])
ids = prueba %>% pull(index)
filas = datos2 %>% filter(index %in% ids)
fold_id[filas$index] = i
}
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = min(cv.out$cvm)))
MSEs
coef(cv.out, s = "lambda.min")
datos2 <- datos %>% # dataframe auxiliar para obener los id de los k-folds
mutate(index = row_number())
# Se crean los k-fols igual que en el modelo normal
set.seed(123)
folds <- vfold_cv(datos2, v = 10)
fold_id <- rep(0, nrow(datos2)) # id's de los k-folds
for(i in 1:10){
prueba = assessment(folds$splits[[i]])
ids = prueba %>% pull(index)
filas = datos2 %>% filter(index %in% ids)
fold_id[filas$index] = i
}
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = min(cv.out$cvm)))
MSEs
coef(cv.out, s = "lambda.min")
coef(cv.out, s = "lambda.min")
datos2 <- datos %>% # dataframe auxiliar para obener los id de los k-folds
mutate(index = row_number())
# Se crean los k-fols igual que en el modelo normal
set.seed(123)
folds <- vfold_cv(datos2, v = 10)
fold_id <- rep(0, nrow(datos2)) # id's de los k-folds
for(i in 1:10){
prueba = assessment(folds$splits[[i]])
ids = prueba %>% pull(index)
filas = datos2 %>% filter(index %in% ids)
fold_id[filas$index] = i
}
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRM_R + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_R", MSE = mean((lasso.pred - y.test)^2)))
MSEs
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = min(cv.out$cvm)))
MSEs
coef(cv.out, s = "lambda.min")
datos2 <- datos %>% # dataframe auxiliar para obener los id de los k-folds
mutate(index = row_number())
# Se crean los k-fols igual que en el modelo normal
set.seed(123)
folds <- vfold_cv(datos2, v = 10)
fold_id <- rep(0, nrow(datos2)) # id's de los k-folds
for(i in 1:10){
prueba = assessment(folds$splits[[i]])
ids = prueba %>% pull(index)
filas = datos2 %>% filter(index %in% ids)
fold_id[filas$index] = i
}
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRM_90 + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_90", MSE = mean((lasso.pred - y.test)^2)))
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_R", MSE = min(cv.out$cvm)))
coef(cv.out, s = "lambda.min")
MSEs[5:8,]
# Chunk 1
# Librerias
library(readxl)
library(tidyverse)
library(nortest)
library(dplyr)
library(ggplot2)
library(GGally) # para la funcion ggpairs
library(gt)
library(gtExtras)
library(moments)
library(leaps)
library(MASS)
library(lmtest)
library(car)
library(BSDA) # Test del signo
library(glmnet)
library(glmtoolbox)
library(MASS)
library(rsample)
library(lawstat)
# Chunk 2
datos <- read_excel("Datos/Corregida - COMPILADO DATOS COMUNIDAD DE CUIDADO Y CENTRO DÍA.xlsx",
range = "B2:AN561", col_types = c("date",
"skip", "text", "text", "text", "skip",
"text", "numeric", "text", "skip",
"skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "skip", "numeric",
"skip", "skip", "skip", "skip", "numeric"))
colnames(datos) <- c("Fecha", "Localidad", "Programa", "Unidad_atencion",
"Sexo", "Edad", "Etnia", "Peso", "Talla",
"LRT_CM","LRT_A", "LRM_90","LRM_R")
datos$Sexo <- as.factor(datos$Sexo)
datos$Etnia <- as.factor(datos$Etnia)
datos <- datos[-which(datos$Edad<60),] # >60
datos <- datos |> filter(!(abs(LRT_A-LRT_CM) > 3 | abs(LRM_90-LRM_R) > 3))
datos <- datos |> as.data.frame()
# Chunk 3
#| results: hide
regfit.full <- regsubsets(Talla ~ LRT_A + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# Chunk 4
reg.summary$bic
# Chunk 5
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Chunk 6
coef(regfit.full, 3)
# Chunk 7
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 8
# Para ir almacenando los MSE de los modelos y las longitudes
MSEs <- data.frame(Modelo = character(),
Medida = character(),
MSE = numeric())
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRT_A", MSE = mean(errores)))
# Chunk 9
#| results: hide
regfit.full <- regsubsets(Talla ~ LRT_CM + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
# Chunk 10
reg.summary$bic
# Chunk 11
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Chunk 12
coef(regfit.full, 3)
# Chunk 13
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_CM + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 14
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRT_CM", MSE = mean(errores)))
# Chunk 15
#| results: hide
regfit.full <- regsubsets(Talla ~ LRM_R + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# Chunk 16
reg.summary$bic
# Chunk 17
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Chunk 18
coef(regfit.full, 3)
# Chunk 19
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_R + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 20
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_R", MSE = mean(errores))) # No se incluye pq aparentemente hay una leve homocedasticidad en los errores
# Chunk 21
#| results: hide
regfit.full <- regsubsets(Talla ~ LRM_90 + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
# Chunk 22
reg.summary$bic
# Chunk 23
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Chunk 24
coef(regfit.full, 3)
# Chunk 25
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_90 + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Chunk 26
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_90", MSE = mean(errores))) # No se incluye pq el modelo no está bien especificado
# Chunk 27
MSEs[1:4,]
# Chunk 28
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
# Chunk 29
plot(reg, which = 1)
# Chunk 30
dwtest(reg)
# Chunk 31
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
# Chunk 32
plot(reg, which = 3)
# Chunk 33
bptest(reg)
# Chunk 34
vif(reg)
# Chunk 35
resettest(reg, type="regressor")
resettest(reg, type="fitted")
# Chunk 36
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
# Chunk 37
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
# Chunk 38
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})
summary(reg2)
datos2 <- datos %>% # dataframe auxiliar para obener los id de los k-folds
mutate(index = row_number())
# Se crean los k-fols igual que en el modelo normal
set.seed(123)
folds <- vfold_cv(datos2, v = 10)
fold_id <- rep(0, nrow(datos2)) # id's de los k-folds
for(i in 1:10){
prueba = assessment(folds$splits[[i]])
ids = prueba %>% pull(index)
filas = datos2 %>% filter(index %in% ids)
fold_id[filas$index] = i
}
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = min(cv.out$cvm)))
coef(cv.out, s = "lambda.min")
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = min(cv.out$cvm)))
coef(cv.out, s = "lambda.min")
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRM_R + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_R", MSE = min(cv.out$cvm)))
coef(cv.out, s = "lambda.min")
# Matriz diseño y variable respuesta
x <- model.matrix(Talla ~ LRM_90 + Edad + Sexo + Etnia, data = datos)[,-1]
y <- datos$Talla
grid <- 10^seq(3, -3, length.out = 500) # grilla de valores lambda
# alpha = 1 se refiere a LASSO
cv.out <- cv.glmnet(x, y, alpha = 1, lambda = grid, foldid = fold_id, type.measure = "mse")
plot(cv.out) # muestra dónde se miniza la función de pérdida
cv.out$lambda.min # Mejor lambda
min(cv.out$cvm) # Este es el MSE promedio de los 10 folds
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_90", MSE = min(cv.out$cvm)))
coef(cv.out, s = "lambda.min")
coef(cv.out, s = "lambda.min")
MSEs[5:8,]
paste("Valor de lambda óptimo:", cv.out$lambda.min) # Mejor lambda
paste("Valor de lambda óptimo:", round(cv.out$lambda.min,3)) # Mejor lambda
paste("Valor de lambda óptimo:", round(cv.out$lambda.min,3)) # Mejor lambda
paste("MSE:", round(min(cv.out$cvm),3)) # Este es el MSE promedio de los 10 folds
