folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Para ir almacenando los MSE de los modelos y las longitudes
MSEs <- data.frame(Modelo = character(),
Medida = character(),
MSE = numeric())
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRT_A", MSE = mean(errores)))
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,504))})
summary(reg2)
regfit.full <- regsubsets(Talla ~ LRM_R + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_R", MSE = mean(errores)))
coef(regfit.full, 3)
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
coef(regfit.full, 3)
reg <- lm(Talla ~ LRM_CM + Edad + Sexo, data = datos)
reg <- lm(Talla ~ LRM_R + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
dwtest(reg)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
plot(reg, which = 3)
bptest(reg)
vif(reg)
resettest(reg, type="regressor")
resettest(reg, type="fitted")
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
#| layout-ncol: 2
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,542,504))})
summary(reg2)
regfit.full <- regsubsets(Talla ~ LRM_90 + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_90", MSE = mean(errores)))
reg <- lm(Talla ~ LRM_90 + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
dwtest(reg)
plot(reg, which = 3)
vif(reg)
resettest(reg, type="regressor")
resettest(reg, type="fitted")
#| layout-ncol: 2
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(80,147,533))})
summary(reg2)
View(MSEs)
x <- model.matrix(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:12, ]
lasso.coef
lasso.coef[lasso.coef != 0]
View(MSEs)
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:12, ]
lasso.coef <- predict(out , type = "coefficients", s = bestlam)
View(lasso.coef)
lasso.coef
lasso.coef[lasso.coef != 0]
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRM_R + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
x <- model.matrix(Talla ~ LRM_90 + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef[lasso.coef != 0]
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_A + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
k = 10
for (j in 1:k) {
best.fit <- lapply(forms_gamma, function(formula){
glm(formula, family = Gamma(), data = datos[folds != j, ])
})
#for (i in 1:length(forms_gamma)) {
pred <- lapply(best.fit, function(model){
predict(model, datos[folds == j, ], type = "response")
})
cv.errors <- lapply(pred, function(coefs){
mean((datos$Talla[folds == j] - coefs)^2)
})
cv.errors <- as.data.frame(cv.errors)
colnames(cv.errors) <- c(paste("Mod", 1:length(forms_gamma)))
CV.ERRORS <- rbind(CV.ERRORS, cv.errors)
#}
}
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Error cuadratico medio
mean(errores)
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
#
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRT_A + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
# StepCriterion
#sc <- stepCriterion(gamma.reg, direction="backward", criterion="aic", test="wald")
# Ajuste con stepAIC, guardando resultados intermedios
# Forward
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
gamma.reg <- glm(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Etnia + Peso + Sexo + Programa, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
modelos_intermedios <- list()
# Función para guardar modelos en cada paso
guardar_modelos <- function(object, ...) {
modelos_intermedios[[length(modelos_intermedios) + 1]] <<- object
FALSE  # Devuelve FALSE para continuar con el proceso
}
# Selección hacia adelante con BIC y almacenamiento de modelos intermedios
stepwise <- stepAIC(
gamma.reg_null,
scope = list(lower = gamma.reg_null, upper = gamma.reg),
direction = "forward",
trace = TRUE,
k = log(nrow(datos)),  # Usar BIC en lugar de AIC
keep = guardar_modelos  # Guardar cada modelo intermedio
)
forms_gamma <- lapply(modelos_intermedios, formula)
#forms_gamma
#kfolds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
k = 10
for (j in 1:k) {
best.fit <- lapply(forms_gamma, function(formula){
glm(formula, family = Gamma(), data = datos[folds != j, ])
})
#for (i in 1:length(forms_gamma)) {
pred <- lapply(best.fit, function(model){
predict(model, datos[folds == j, ], type = "response")
})
cv.errors <- lapply(pred, function(coefs){
mean((datos$Talla[folds == j] - coefs)^2)
})
cv.errors <- as.data.frame(cv.errors)
colnames(cv.errors) <- c(paste("Mod", 1:length(forms_gamma)))
CV.ERRORS <- rbind(CV.ERRORS, cv.errors)
#}
}
summary(gamma.reg)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_A + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_A + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRT_A + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRM_R + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRM_R + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRM_R", MSE = mean(errores)))
table(datos$Etnia)
blmt <- datos[datos$Etnia=="Blanco-Mestizo",]
regfit.full <- regsubsets(Talla ~ LRT_A + Edad + Sexo,
blmt, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
blmt <- datos[datos$Etnia=="Blanco-Mestizo",]
regfit.full <- regsubsets(Talla ~ LRT_A + Edad + Sexo,
blmt, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(blmt, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Para ir almacenando los MSE de los modelos y las longitudes
MSEs_blmt <- data.frame(Modelo = character(),
Medida = character(),
MSE = numeric())
# Promedio del error cuadrático medio
mean(errores)
MSEs_blmt <- rbind(MSEs_blmt, data.frame(Modelo = "Normal", Medida = "LRT_A", MSE = mean(errores)))
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = blmt)
(summary.reg <- summary(reg))
plot(reg, which = 1)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
