{"title":"Caso 1 de Consultoría: Comparación de la talla estimada mediante ecuaciones de predicción en adultos mayores.","markdown":{"yaml":{"title":"Caso 1 de Consultoría: Comparación de la talla estimada mediante ecuaciones de predicción en adultos mayores.","author":[{"name":"Ana Sofia Bello, Karol Ayala, Carlos Mario Castaño, Jesus Zisa","affiliation":"Departamento de estadística - Universidad Nacional de Colombia."}],"address":["Departamento de estadística - Universidad Nacional de Colombia."],"format":{"html":{"grid":{"body-width":"1100px","sidebar-width":"400px","margin-width":"100px","gutter-width":"1em"},"toc-location":"left"}},"toc":true,"echo":false,"code-fold":true,"code-summary":"","warning":false,"editor_options":{"chunk_output_type":"console"}},"headingText":"Librerias","containsRefs":false,"markdown":"\n\n```{r}\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(nortest)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(GGally) # para la funcion ggpairs\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(moments)\nlibrary(leaps)\nlibrary(MASS)\nlibrary(lmtest)\nlibrary(car)\nlibrary(BSDA) # Test del signo\nlibrary(glmnet)\nlibrary(glmtoolbox)\nlibrary(MASS)\n```\n\n## Lectura de datos\n \nSe muestra a continuación la forma que tienen los datos.  \n \n```{r}\n# Lectura base de datos\ndatos <- read_excel(\"Datos/Corregida - COMPILADO DATOS COMUNIDAD DE CUIDADO Y CENTRO DÍA.xlsx\", \n                      range = \"B2:AN561\", col_types = c(\"date\", \n                      \"skip\", \"text\", \"text\", \"text\", \"skip\", \n                      \"text\", \"numeric\", \"text\", \"skip\", \n                      \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\"))\ncolnames(datos) <- c(\"Fecha\", \"Localidad\", \"Programa\", \"Unidad_atencion\", \n                     \"Sexo\", \"Edad\", \"Etnia\", \"Peso\", \"Talla\",\n                     \"LRT_CM\",\"LRT_A\", \"LRM_90\",\"LRM_R\")\ndatos$Sexo <- as.factor(datos$Sexo)\ndatos$Etnia <- as.factor(datos$Etnia)\ndatos <- datos[-which(datos$Edad<60),] # >60\ndatos <- datos |> as.data.frame()\nhead(datos) |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\n## Análisis descriptivo\n\n### Distribución, atípicos y test de normalidad\n\n#### Sexo\n\n```{r}\n#| layout-ncol: 2\n\n# summary(datos$Sexo)\n# summary(datos$Sexo)/length(datos$Sexo)\n\ndatos_resumen <- datos %>%\n  dplyr::count(Sexo) %>%\n  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3))\ndatos_resumen |> gt() |> gtExtras::gt_theme_538()\n\nggplot(datos_resumen, aes(x = \"\", y = porcentaje, fill = Sexo)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +  # Elimina fondo y ejes\n  labs(title = \"Porcentaje de Hombres y Mujeres\", fill = \"Sexo\") +\n  geom_text(aes(label = paste0(round(porcentaje, 1), \"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\")\n```\n\nLa muestra cuenta con 284 personas de sexo femenino y 275 masculino\n\n#### Edad\n\nResumen de la variable `Edad`:\n\n```{r}\nsummary(datos$Edad)\n```\n\nDistribución de la variable `Edad`\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Edad, freq=FALSE, main = 'Hstograma de Edad', xlab = 'Edad', ylab = 'Densidad')\nlines(density(datos$Edad), col =\"red\")\nbox_Edad <- boxplot(datos$Edad)\n```\n\nDatos atípicos en la variable `Edad`:\n\n```{r}\ndatos[which(datos$Edad>box_Edad$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> \n  tab_options(table.font.size = 9)\n```\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Edad) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Edad, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Edad) # No se tiene normalidad en la edad según el test de lillie\n```\n\nEl mínimo de edad en la muestra es `r summary(datos$Edad)[1]` años, el máximo son `r max(datos$Edad)` años, la media es `r mean(datos$Edad)` años y la mediana es de`median(datos$Edad)` años. Existen dos datos atípicos: 93 y 95 años. \nNo hay evidencia estadística de que la edad siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 4.496e-09, y el test Lilliefors muestra un p-valor de 1.168e-09. \n\n\n#### Etnia\n\nResumen de la variable `Etnia`:\n\n```{r}\ndatos %>%\n  dplyr::count(Etnia) %>%\n  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3)) |> \n  gt() |> gtExtras::gt_theme_538()\n# No se debería incluír un factor tan sesgado en el modelo\n# Se puede tener en cuenta, sin embargo\n```\n\n\n#### Peso\n\nResumen de la variable `Peso`:\n\n```{r}\nsummary(datos$Peso)\n```\n\nDistribución de la variable `Peso`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Peso, freq = FALSE, main = 'Histograma del peso', xlab = 'Peso', ylab = 'Densidad')\nlines(density(datos$Peso), col = \"red\")\nbox_peso <- boxplot(datos$Peso)\n```\n\nTenemos los siguientes datos atípicos en la variable `Peso`:\n\n```{r}\ndatos[which(datos$Peso>box_peso$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `Peso` distinguiendo por `Sexo`:\n\n```{r}\nbox_peso_fm <- boxplot(datos$Peso ~ datos$Sexo, xlab = 'Sexo', ylab = 'Peso')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$Peso>box_peso_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$Peso>box_peso_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 8)\n```\n:::\n\nEn resúmen el mínimo de peso en la muestra es 34.20 kg, el máximo son 101.8 kg, la media son 63.34 kg y la mediana 62.8 kg. En la muestra junta, tenemos $8$ datos atípicos $101.80, 98.70, 97.65, 97.40, 97.10, 95.60, 95.10$ y $94.20$.  Cuando se separa por Sexo, tenemos $2$ datos atípicos en Femenino (97.10 y 91.6), y $4$ en Masculino (101.80, 98.70, 97.65 y 97.40). \n\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Peso) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Peso) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que el peso siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 7.563e-05 y el test Lilliefors muestra un p-valor de 0.047304. \n\n#### Talla\n\nResumen de la variable `Talla`:\n\n```{r}\nsummary(datos$Talla)\n```\n\nDistribución de la variable `Talla`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Talla, freq = FALSE, main = 'Histograma de Talla', xlab= 'Talla', ylab = 'Densidad')\nlines(density(datos$Talla), col = \"red\")\nbox_talla <- boxplot(datos$Talla)\n```\n\nTenemos un dato atípico en la variable `Talla`:\n\n```{r}\ndatos[which(datos$Talla<box_talla$stats[1]|datos$Talla>box_talla$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistinguiendo por `Sexo`:\n\n```{r}\nbox_talla_fm <- boxplot(datos$Talla ~ datos$Sexo, xlab='Sexo', ylab='Talla')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$Talla<box_talla_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$Talla>box_talla_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nEn hombres: \n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$Talla<box_talla_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$Talla>box_talla_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEn resúmen, el mínimo de talla en la muestra es 127.1 cm, el máximo son 181.5 cm, la media son 155.95 cm y la mediana 155.15 cm. En la muestra junta, tenemos un dato atípico (127.1). Cuando se separa por Sexo, hay tres datos atípicos en Femenino (133.00, 133.85, 127.10, 129.25 y 132.55, 133.90) y en Masculino dos (142.00 y 141.50). \n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Talla) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Talla) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nEl test Shapiro-Wilk arrojó un p-valor 0.05641 sugiriendo normalidad pero sin ser muy significativo, mientras que el test Lilliefors muestra un p-valor de 0.04836, por lo que no habría normalidad.\n\n\n\n#### Longitud Rodilla Talón con cinta métrica `LRT_CM`\n\nResumen de la variable `LRT_CM`:\n\n```{r}\nsummary(datos$LRT_CM)\n```\n\nDistribución de la variable `LRT_CM`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRT_CM, freq = FALSE, main = 'Histograma de LRT medido con cinta métrica', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRT_CM), col = \"red\")\nbox_LRT_CM <- boxplot(datos$LRT_CM)\n```\n\nDatos atípicos:\n\n```{r}\ndatos[which(datos$LRT_CM<box_LRT_CM$stats[1]|datos$LRT_CM>box_LRT_CM$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRT_CM` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRT_CM_fm <- boxplot(datos$LRT_CM ~ datos$Sexo, xlab='Sexo', ylab='Longitud en cm')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRT_CM<box_LRT_CM_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRT_CM>box_LRT_CM_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRT_CM<box_LRT_CM_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRT_CM>box_LRT_CM_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nPruebas de Normalidad:\n\nEn resúmen, el mínimo de LRT con cinta métrica en la muestra es 38 cm, el máximo son 59 cm, la media son 49 cm y la mediana 48.65 cm. En la muestra junta, parece haber tres datos atípicos (59, 39 y 38), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (39 y 38) y uno en Masculino (59). \n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que la LRT con cinta métrica siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.02391, y el test Lilliefors muestra un p-valor de 0.01056.\n\n#### Longitud Rodilla Talón con Antropómetro `LRT_A`: \n\nResumen de la variable `LRT_A`:\n\n```{r}\nsummary(datos$LRT_A)\n```\n\nDistribución de la variable `LRT_A`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRT_A, freq = FALSE, main ='Histograma de LRT con antropómetro', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRT_A), col = \"red\")\nbox_LRT_A <- boxplot(datos$LRT_A)\n```\n\nDatos atípicos en la variable `LRT_A`:\n\n```{r}\ndatos[which(datos$LRT_A<box_LRT_A$stats[1]|datos$LRT_A>box_LRT_A$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRT_A` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRT_A_fm <- boxplot(datos$LRT_A ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRT con antropómetro en cm')\n```\n\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRT_A<box_LRT_A_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRT_A>box_LRT_A_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRT_A<box_LRT_A_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRT_A>box_LRT_A_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEn resúmen, el mínimo de LRT con antropómetro en la muestra es 36.85 cm, el máximo son 58.35 cm, la media son 47.54 cm y la mediana 47.4 cm. En la muestra junta, tenemos 3 datos atípicos (58.35, 37.00 y 36.85). Cuando se separa por Sexo, parece haber tres datos atípicos en Femenino (37.00, 36.85 y 38.20) y en Masculino dos (57.65 y 58.35).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que la LRT con antropómetro siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.0507 (no es muy significativo), y el test Lilliefors muestra un p-valor de 0.01345. \n\n#### Longitud Rodilla-Maléolo a 90° `LRM_90`\n\nResumen de la variable `LRM_90`:\n\n```{r}\nsummary(datos$LRM_90)\n```\n\nDistribución de la variable `LRM_90`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRM_90, freq = FALSE, main = 'Histograma de LRM a 90°', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRM_90), col = \"red\")\nbox_LRM_90<- boxplot(datos$LRM_90)\n```\n\nDatos atípicos en la variable `LRM_90`:\n\n```{r}\ndatos[which(datos$LRM_90<box_LRM_90$stats[1]|datos$LRM_90>box_LRM_90$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRM_90` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRM_90_fm <- boxplot(datos$LRM_90 ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM a 90° en cm')\n```\n\n\nDatos atípicos en mujeres cuando se distingue por `Sexo`:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRM_90<box_LRM_90_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRM_90>box_LRM_90_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos en hombres cuando se distingue por `Sexo`:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRM_90<box_LRM_90_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRM_90>box_LRM_90_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEl mínimo de LRM con la pierna a 90° en la muestra es 31.85 cm, el máximo son 54.65 cm, la media son 43.33 cm y la mediana 43.2 cm. En la muestra junta, tenemos 6 datos atípicos (53.00, 54.65, 52.30, 52.30, 34.00, 31.85). Cuando se separa por Sexo, tenemos 2 datos atípicos en Femenino (34.00 y 31.85), y en Masculino 2 (53.00, 54.65).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nCon el test Shapiro-Wilk no tenemos normalidad en distribución pues tenemos un p-valor de 0.01393, mientras que el test Lilliefors muestra un p-valor de 0.001307, por lo que no habría normalidad.\n\n#### Longitud Rodilla-Maléolo la pierna totalmente estirada `LRM_R`\n\nResumen de la variable `LRM_R`:\n\n```{r}\nsummary(datos$LRM_R)\n```\n\nDistribución de la variable `LRM_R`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRM_R, freq = FALSE, main = 'Histograma de LRM recta', xlab = 'Longitud en cm', ylab='Densidad')\nlines(density(datos$LRM_R), col = \"red\")\nbox_LRM_R<- boxplot(datos$LRM_R)\n```\n\nDatos atípicos en la variable `LRM_R`:\n\n```{r}\ndatos[which(datos$LRM_R<box_LRM_R$stats[1]|datos$LRM_R>box_LRM_R$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRM_R` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRM_R_fm <- boxplot(datos$LRM_R ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM recta en cm')\n```\n\n\nDatos atípicos en mujeres cuando se distingue por `Sexo`:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRM_R<box_LRM_R_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRM_R>box_LRM_R_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos en hombres cuando se distingue por `Sexo`:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRM_R<box_LRM_R_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRM_R>box_LRM_R_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEl mínimo de LRM con la pierna recta en la muestra es 31.45 cm, el máximo son 52.5 cm, la media son 42.54 cm y la mediana 42.50 cm. En la muestra junta, parece haber un dato atípico (31.45), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (33.50 y 31.45), y en Masculino cuatro (52.50, 51.35, 52.50, 51.25, 37.70 y 37.75).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nCon el test Shapiro-Wilk parece haber normalidad pues tenemos un p-valor de 0.09192, mientras que el test Lilliefors muestra un p-valor de 0.004743, por lo que no habría normalidad.\n\n### Análisis de correlación\n\n```{r}\nggpairs(\n  datos[,-c(1:5, 7)],  # Tu subconjunto de datos\n  lower = list(continuous = wrap(\"smooth\", method = \"lm\", color = \"lightblue\")),  # Línea de regresión en rojo\n  title = \"Matriz de correlaciones\"\n)\n```\n\nExiste una fuerte correlación lineal positiva entre la variable talla y cada una de las mediciones de la longitud rodilla-talón y rodilla-maléolo, considerarlas para los diferentes modelos de regresión parece ser una buena opción. La talla está correlacionada con el peso de forma moderada, por lo que valdría la pena explorar su contribución en los modelos propuestos. No parece haber una correlación lineal significativa entre la talla y la edad, sugiriendo que no sería necesario incluir la edad en los modelos propuestos.\n\nEn principio, dado que la relación entre cada una de las medidas de la longitud rodilla-talón y rodilla-maléolo presentan una relación lineal fuerte con la talla, se podría pensar que la que tenga una mayor correlación con la talla, es la que daría mejores estimaciones de la talla real. En este caso, la longitud rodilla-talón con antropómetro, es la que presenta una mayor correlación con la talla, por lo que posiblemente sea más preciso usar esta medida para estimar la talla real de los adultos mayores. Como sabemos, el antropómetro es una herramienta que no siempre es de fácil acceso y justamente queremos evaluar si existen diferencias significativas entre usar esta medición y las demás mediciones que sí son de fácil acceso y aplicación.\n\nEn ese orden de ideas, después de la longitud de rodilla talón con antropómetro, la longitud rodilla-talón con cinta métrica es la variable que tiene más correlación con la talla, luego sigue la longitud rodilla-maléolo con la pierna totalmente estirada y por último la longitud rodilla-maléolo con la pierna a 90 grados.\n\n## Hipótesis\n\n### Longitud rodilla-talón\n\nInicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:\n\n```{r}\n# Comparar LRT CM y A\nboxplot(data.frame(datos$LRT_CM, datos$LRT_A))\n```\n\nSegún el gráfico de cajas (boxplot), parece que hay una pequeña diferencia entre las mediciones de la longitud desde la rodilla hasta el talón realizadas con cinta métrica y con antropómetro. Sin embargo, para estar seguros, es necesario hacer una prueba estadística más formal. Para esto, se calculan las diferencias entre las mediciones de ambos métodos y se verifica si esas diferencias siguen una distribución normal. Dependiendo del resultado, se elegirá la prueba estadística adecuada para comprobar si realmente no hay una diferencia significativa entre ambos tipos de medición.\n\n```{r}\n# Diferencias CM y A\nLRT_dif <- datos$LRT_CM - datos$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro sigan una distribución normal. Por lo tanto, es necesario usar un tipo de prueba estadística diferente, que no dependa de suposiciones sobre la distribución de los datos, para analizar las diferencias en los promedios.\n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\n## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)\n\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\n\nAl principio, se pensó en usar la prueba de Wilcoxon, que es una prueba estadística no paramétrica para evaluar el promedio de las diferencias. Sin embargo, esta prueba asume que las diferencias entre las mediciones son simétricas, pero eso no ocurrió en nuestros datos, ya que el coeficiente de asimetría fue de -0.785, lo que muestra que las diferencias no son simétricas. Por eso, se decidió usar una prueba diferente llamada \"prueba del signo para muestras pareadas\", que no necesita asumir normalidad ni simetría. Aunque esta prueba no da información sobre el promedio de las diferencias, sí permite evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro.\n\n#### Análisis por separado\n\n##### Por sexo\n###### Masculino:\n\n```{r}\n# Diferencias CM y A\nhombres <- datos[datos$Sexo == \"Masculino\",]\nLRT_dif <- hombres$LRT_CM - hombres$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de sexo masculino sigan una distribución normal. \n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.69. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores de sexo masculino.\n\n###### Femenino:\n```{r}\n# Diferencias CM y A\nmujeres <- datos[datos$Sexo == \"Femenino\",]\nLRT_dif <- mujeres$LRT_CM - mujeres$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en las mujeres mayores sigan una distribución normal. \n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en las mujeres mayores.\n\n##### Por programa\n\n###### Centro día:\n```{r}\n# Diferencias CM y A\ncd <- datos[datos$Programa == \"Centro Día Casa de la Sabiduría\",]\nLRT_dif <- cd$LRT_CM - cd$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores del centro día sigan una distribución normal. \n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores del centro día.\n\n###### Comunidad de cuidado\n```{r}\n# Diferencias CM y A\ncc <- datos[datos$Programa == \"Comunidad de Cuidado\",]\nLRT_dif <- cc$LRT_CM - cc$LRT_A\n\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de las comunidades de cuidado sigan una distribución normal. \n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se aplica Wilcoxon \n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.64. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro,  en los adultos mayores de las comunidades de cuidado.\n\n##### Por etnia\n\n###### Blanco-Mestizo\n```{r}\n# Diferencias CM y A \nbm <- datos[datos$Etnia==\"Blanco-Mestizo\",]\nLRT_dif <- bm$LRT_CM - bm$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores Blancos-Mestizos sigan una distribución normal. \n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se aplica Wilcoxon \n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -0.78. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores Blancos-Mestizos.\n\n###### Afrocolombiano, indigenas, Rrom \n\n```{r}\n# Diferencias CM y A \nnobm <- datos[datos$Etnia!=\"Blanco-Mestizo\",]\nLRT_dif <- nobm$LRT_CM - nobm$LRT_A\n#length(LRT_dif)\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # No hay outliers\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # Se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # Se tiene normalidad según el test de Lilliefors\n```\nUno de los resultados de las pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostró un valor menor a 0.05 y la otra un valor mayor. Dado que de estas etnias solo hay 12 adultos mayores, las pruebas son más sensibles y pueden dar resultados menos confiables. Por esa razón, se va a evaluar la simetría de las diferencias para no realizar la prueba que asume normalidad.\n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Sin embargo, la prueba no puede calcular el p-valor exacto debido a la presencia de valores repetidos en las diferencias, por lo que se va a realizar el test del signo.\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nEl resultado de la prueba del signo mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores afrocolombiano, indigenas o Rrom.\n\n\n### Longitud rodilla-maléolo\n\nInicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:\n\n```{r}\n# Comparar LRM 90 y R\nboxplot(data.frame(datos$LRM_90, datos$LRM_R))\n```\n\nSegún el boxplot, se puede observar que sí existe una leve diferencia entre las distribuciones de las mediciones de la longitud rodilla maléolo con la pierna a 90° y con la pierna completamente estirada. Sin embargo, es necesario, realizar una prueba estadística formal para concluir algo, por lo que se calculan las diferencias entre ambos métodos y se les aplica un test de normalidad para elegir qué prueba utilizar para evaluar la hipótesis nula de que la medición longitud rodilla-maléolo con la pierna completamente estirada es igual a la medición de la longitud rodilla-maléolo con la pierna a $90°$.\n\n```{r}\n# Diferencias CM y A\nLRM_dif <- datos$LRM_90 - datos$LRM_R\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRM_dif)\nboxplot(LRM_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRM_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRM_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nDado que en ambos test, Shapiro-Wilk y Lilliefors, se obtuvo un p-valor menor a $0.05$, entonces, con una significancia del $5\\%$, no hay evidencia estadística de que las diferencias entre las mediciones rodilla-talón con cinta métrica y con antropómetro sigan una distribució normal. Por lo tanto, se hace necesario realizar un test no paramétrico para media de las diferencias.\n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRM_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRM_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRM_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\n## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)\n\nSIGN.test(LRM_dif, md = 0, alternative = \"two.sided\")\n```\n\nNuevamente, se consideró aplicar la prueba de Wilcoxon para evaluar la media de las diferencias, pero esta prueba no se aplicó ya que el coeficiente de asimetría obtenido fue de $2.022$. Este valor indica una falta de simetría en las diferencias de las mediciones. Por esta razón, de nuevo se optó por utilizar la prueba del signo para muestras pareadas.\n\nEl resultado de la prueba del signo arrojó un p-valor de $2.2 \\times 10^{-16}$, indicando evidencia estadística suficiente para rechazar la hipótesis nula de que la mediana de las diferencias es igual a cero. Por lo tanto, se concluye que las mediciones de la longitud rodilla-maléolo realizadas con la pierna completamente estirada no son equivalentes a las obtenidas con la pierna a $90°$.\n\n### Talla real y estimación Benjumea (LRT) con cinta métrica\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con cinta métrica. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es \"Rrom\", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$benjumea_cm <- ifelse(\n  datos$Sexo == \"Masculino\" & datos$Etnia == \"Blanco-Mestizo\",\n  75.514 + 1.883 * datos$LRT_CM - 0.108 * datos$Edad,\n  ifelse(\n    datos$Sexo == \"Femenino\" & datos$Etnia == \"Blanco-Mestizo\",\n    86.497 + 1.553 * datos$LRT_CM - 0.119 * datos$Edad,\n    ifelse(\n      datos$Sexo == \"Masculino\" & datos$Etnia == \"Indigena\",\n      82.695 + 1.745 * datos$LRT_CM - 0.121 * datos$Edad,\n      ifelse(\n        datos$Sexo == \"Femenino\" & datos$Etnia == \"Indigena\",\n        90.281 + 1.436 * datos$LRT_CM - 0.102 * datos$Edad,\n        ifelse(\n          datos$Sexo == \"Masculino\" & datos$Etnia == \"Afrocolombiano\",\n          79.298 + 1.855 * datos$LRT_CM - 0.141 * datos$Edad,\n          ifelse(\n            datos$Sexo == \"Femenino\" & datos$Etnia == \"Afrocolombiano\",\n            76.233 + 1.767 * datos$LRT_CM - 0.098 * datos$Edad,\n            NA # solo hay un NA que es el Rrom\n          )\n        )\n      )\n    )\n  )\n)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con cinta métrica y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$benjumea_cm))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con cinta métrica, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$benjumea_cm\ntalla_dif <- talla_dif[!is.na(talla_dif)]\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \\times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con cinta métrica no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Benjumea sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$benjumea_cm)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Benjumea (LRT) con antropómetro\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con antropómetro. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es \"Rrom\", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$benjumea_a <- ifelse(\n  datos$Sexo == \"Masculino\" & datos$Etnia == \"Blanco-Mestizo\",\n  75.514 + 1.883 * datos$LRT_A - 0.108 * datos$Edad,\n  ifelse(\n    datos$Sexo == \"Femenino\" & datos$Etnia == \"Blanco-Mestizo\",\n    86.497 + 1.553 * datos$LRT_A - 0.119 * datos$Edad,\n    ifelse(\n      datos$Sexo == \"Masculino\" & datos$Etnia == \"Indigena\",\n      82.695 + 1.745 * datos$LRT_A - 0.121 * datos$Edad,\n      ifelse(\n        datos$Sexo == \"Femenino\" & datos$Etnia == \"Indigena\",\n        90.281 + 1.436 * datos$LRT_A - 0.102 * datos$Edad,\n        ifelse(\n          datos$Sexo == \"Masculino\" & datos$Etnia == \"Afrocolombiano\",\n          79.298 + 1.855 * datos$LRT_A - 0.141 * datos$Edad,\n          ifelse(\n            datos$Sexo == \"Femenino\" & datos$Etnia == \"Afrocolombiano\",\n            76.233 + 1.767 * datos$LRT_A - 0.098 * datos$Edad,\n            NA # solo hay un NA que es el Rrom\n          )\n        )\n      )\n    )\n  )\n)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con antropómetro y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$benjumea_a))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con antropómetro, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$benjumea_a\ntalla_dif <- talla_dif[!is.na(talla_dif)]\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $4.103 \\times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con antropómetro no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Benjumea sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$benjumea_a)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Arango Zamor (LRM) a $90°$\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo a $90°$.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$arango_90 <- ifelse(\n  datos$Sexo == \"Masculino\",\n  119.6 + 1.121*datos$LRM_90 - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_90 - 0.159*datos$Edad)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$ y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$arango_90))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$arango_90\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $9.685 \\times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna a $90°$ no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$arango_90)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Arango Zamor (LRM) con la pierna estirada\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo con la pierna estirada.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$arango_r <- ifelse(\n  datos$Sexo == \"Masculino\",\n  119.6 + 1.121*datos$LRM_R - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_R - 0.159*datos$Edad)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna estirada y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$arango_r))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a estirada, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$arango_r\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \\times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna estirada no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$arango_r)^2, na.rm = TRUE)\n```\n\n## Modelos\n\nA continuación el resumen de la evaluación de las hipótesis de interés:\n\n-   La diferencia en las mediciones de LRT con antropómetro y con cinta métrica resultó ser estadísticamente significativa.\n-   La diferencia en las mediciones de LRM con la pierna a $90°$ y la pierna estirada resultó ser estadísticamente significativa.\n\nEstos resultados sigieren que:\n\n-   No es posible determinar que las mediciones de LRT con la cinta métrica sean iguales a las obtenidad con antropómetro. Asumiendo que la medición con antropómetro es más exacta, las mediciones con la cinta métrica suelen sobreestimar en promedio a las del antropómetro.\n-   Tampoco es posible determinar que las mediciones de LRM con la pierna a $90°$ y con la pierna estirada sean iguales. La medición con la pierna estirada suele ser en promedio menor a la medición hecha con la pierna a $90°$.\n\nLos resultados obtenidos al evaluar las fórmulas de ***Benjumea*** y de ***Arango y Zamora*** en mustra de adultos mayores que atiende la SDIS, parecen no tener muy buenos resultados a la hora de estimar la talla de los adultos mayores.\n\nDado estos resultados, se concluye que se requiere de fórmulas específicas para la población que atiende la **SDIS**. Además, se deberá ajustar estos modelos para las cuatro mediciones pues la evaluación de las hipótesis no dieron indicios de la igualdad entre los métodos de las mediciones.\n\n### Selección del mejor modelo usando LRT_A\n\nInicialmente, se hará la selección del mejor modelo para LRT_A mediante un enfoque predictivo.\n\nA continuación se hace una búsqueda del mejor modelo por cada número de posibles combinaciones de variables. Primero se hará la búsqueda usando todo el conjunto de datos.\n\n```{r}\nregfit.full <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa,\n                          datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables \n\n(reg.summary <- summary(regfit.full))\n# names(reg.summary)\n```\n\n$R^2$, $R^2$ ajustado, SCE, y BIC para cada mejor modelo del correspondiente tamaño:\n\n```{r}\nreg.summary$rsq\nreg.summary$adjr2\nreg.summary$rss\nreg.summary$bic\n```\n\nUsando el criterio BIC, el mejor modelo es el de 3 variables:\n\n```{r}\nwhich.min(reg.summary$bic)\nplot(reg.summary$bic , xlab = \"Number of Variables\",\nylab = \"BIC\", type = \"l\")\npoints(3, reg.summary$bic[3], col = \"red\", cex = 2,\npch = 20)\nplot(regfit.full , scale = \"bic\")\n```\n\nUsando el $R^2$ ajustado, se sugiere un modelo con 5 variables:\n\n```{r}\nplot(regfit.full , scale = \"adjr2\")\n```\n\nLos coeficientes del mejor modelo usando el criterio de BIC son:\n\n```{r}\ncoef(regfit.full, 3)\n```\n\nEsto sugiere usar el modelo $Talla = 58.67 + 2.19 LRT\\_A - 0.12Edad + 3.06Sexo$,\\\n$$Sexo = \\begin{cases} 1 & \\text{si sexo = hombre} \\\\ 0 & \\text{si sexo = mujer} \\end{cases}$$\n\nAhora se hará la búsqueda del mejor modelo usando ***K - fold cross validation*** con el fin de calcular directamente los errores de predicción sobre los datos de testeo y evitar así el sobreajuste.\n\n-   Se crean ***K - folds*** (pliegues) de aproximadamente igual tamaño. En este caso fijamos $k = 10$. Como tenemos $558$ datos, cada pliegue será de tamaño 55 o 56.\n-   El $k-ésimo$ pliegue servirá para testear, y los demás pliegues se juntan para entrenar los modelos. Osea que se usará un $90\\%$ de los datos para entrenamiento y $10\\%$ para test.\n-   Para $k = 1,\\cdots,10,$ se hace la búsqueda del mejor modelo para cada número de variables y se calcula el MSE.\n-   Luego, se promedia el MSE a través de los $10$ pliegues y se escoge el tamaño de modelo con menor MSE promedio.\n-   Finalmente, se hace la búsqueda del mejor modelo por cada número de variables usando todos los datos disponibles y se escoge el modelo asociado al tamaño del modelo obtenido en la validación cruzada.\n\nTamaño de los pliegues:\n\n```{r}\nk <- 10 # k-folds\nn <- nrow(datos)\nset.seed(123)\nfolds <- sample(rep(1:k, length = n))\ntable(folds) # tamaño de cada k-fold\ncv.errors <- matrix(NA, k, 7, dimnames = list(NULL , paste (1:7))) # Matriz para almacenar los errores\n```\n\nMSE promedio a través de los $10$ pliegues para cada número de variables incluídas en el modelo:\n\n```{r}\n# Función para hacer la predicción de los datos de test en cada k-fold\npredict.regsubsets <- function(object , newdata , id, ...) {\n  form <- as.formula(object$call [[2]])\n  mat <- model.matrix(form , newdata)\n  coefi <- coef(object , id = id)\n  xvars <- names(coefi)\n  mat[, xvars] %*% coefi\n}\n\nfor (j in 1:k) {\n  best.fit <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos[folds != j, ], nvmax = 10)\n  for (i in 1:7) { # Se usa 8 porque los modelos tienen un tamaño máximo de 8 variables en el regsubsets\n  pred <- predict(best.fit , datos[folds == j, ], id = i)\n  cv.errors[j, i] <- mean((datos$Talla[folds == j] - pred)^2)\n  }\n}\n# Hay un pequeño problema de multicolinealidad (parece que sucede cuando se incluye la etnia)\n# por eso en vez del 8 puse 7 (porque generaba un error por multicolinealidad)\n\nmean.cv.errors <- apply(cv.errors , 2, mean, na.rm = TRUE)\nmean.cv.errors # El menor MSE promedio es cuando se usa un modelo con 3 variables\n```\n\nEl MSE se minimiza usando un modelo de 3 variables:\n\n```{r}\npar(mfrow = c(1, 1))\nplot(mean.cv.errors , type = \"b\")\n```\n\nSe busca nuevamente el mejor modelo de tres variables usando todos los datos:\n\n```{r}\n# Se busca nuevamente el mejor modelo de 3 variables\nreg.best <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos, nvmax = 10)\nregbest.summary <- summary(reg.best)\nregbest.summary$bic\n\ncoef(reg.best, 3)\n```\n\nCasualmente volvió a dar el mismo modelo con tres variables que incluye LRT_A, la Edad y el Sexo. Esto es seguramente porque las demás variables no contribuyen significativamente a la presición predictiva de los modelos.\n\nAhora se validarán los supuestos para el mejor modelo obtenido:\n\n```{r}\nreg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)\n(summary.reg <- summary(reg))\n```\n\nEl modelo tiene un $R^2$ ajustado de $0.8861$, es decir que aproximadamente un $88.61\\%$ de la variabilidad de la talla es explicada por LRT_A, la edad y el sexo. \n\n***Linealidad:*** Con el fin de verificar que la relación entre la talla y las variables LRT_A (discriminando por sexo) y la edad es lineal, se visualiza el gráfico de los residuos vs los valores predichos del modelo $\\left(\\hat{e},\\hat{y} \\right)$:\n\n```{r}\nplot(reg, which = 1)\n```\n\nEl gráfico no muestra ningún patrón marcado, la ubicación de los puntos parece ser aleatoria alrededor de cero, indicando también homoscedasticidad en los residuales y posible independencia de los mismos. El gráfico muestra algunos valores atípicos que valdría la pena explorar.\n\n***Independencia de los errores:*** Aunque nuestros datos no son temporales, el test de Durbin-Watson nos puede ayudar a evaluar la autocorrelación de los errores del modelo:\n\n```{r}\ndwtest(reg)\n```\n\nLa estadística del test de Durbin-Watson es muy cercano a $2$, se concluye que los errores son independientes.\n\n***Normalidad de los errores:*** Se realiza el gráfico QQ-plot para comparar la distribución de los residuales del modelo con la distribución teórica de una normal. También se hace el test de normalidad de Lilliefors y Anderson-Darling:\n\n```{r}\nplot(reg, which = 2)\nlillie.test(reg$residuals)\nad.test(reg$residuals)\n```\n\nEl QQ-plot muestra que los residuales se ajustan aceptablemente a una distribución normal. Las pruebas de normalidad de Lilliefors y Anderson-Darling también apoyan este resultado.\n\n***Homoscedasticidad:*** Aunque no se vio un patron que indicara heteroscedasticidad en el gráfico de los residuales vs los valores predichos, a continuación se muestra el gráfico de los residuales estandarizados vs los valores predichos con el fin de mejorar la interpretabilidad de la homoscedasticidad y tener una visión más clara de las observaciones atípicas e influyentes:\n\n```{r}\nplot(reg, which = 3)\n```\n\nNo se observan patrones que indiquen hereroscedasticidad en los residuos (forma de cono o embudo). Se siguien observando algunas observaciones atípicas y/o influyentes.\n\nAdicional, se realiza la prueba de Breusch-Pagan para verificar la homoscedasticidad de los residuales:\n\n```{r}\nbptest(reg)\n```\n\nNo se rechaza la hipótesis nula de que los errores del modelo son homoscedasticos.\n\n***Multicolinealidad:*** Se verifica que las variables incluídas en el modelo no están altamente correlacionadas entre sí, y así evitar obtener resultados inestables que dificulten la interpretabilidad de los coeficientes del modelo. Se calculan los Factores de Inflación de la Varianza (VIFs):\n\n```{r}\nvif(reg)\n```\n\nDado que los VIFs son mucho menores a 5, esto indica que cada variable tiene una correlación moderada (leve) con las demás. Por lo que se puede concluir que los resultados del modelo posiblemente no estarán muy afectados por la multicolinealidad.\n\n***El modelo está bien especificado:*** Se hace el test de RESET para examinar si el modelo ajustado está bien especificado o si se han omitido términos no lineales o interacciones importantes:\n\n```{r}\nresettest(reg, type=\"regressor\")\nresettest(reg, type=\"fitted\")\n```\n\nNo se rechaza la hipótesis nula de que el modelo está bien especificado.\n\n***Obervaciones atípicas y de alto apalancamiento:*** \n\n```{r}\n#| layout-ncol: 2\nplot(reg,which=5)\nstud_res<-studres(reg)\n# head(sort(abs(stud_res),decreasing=TRUE))\nboxplot(stud_res)\n```\n\nUsando los residuales estudentizados, se observan $5$ datos atípicos.\n\n```{r}\n#| layout-ncol: 2\ncorte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica\nplot(reg, which=4, cook.levels=corte)\nabline(h=corte, lty=2, col=\"red\")\ncooksd<-cooks.distance(reg)\n# cooksd[which(cooksd>corte)]\n\ninfluencePlot(reg, id.method=\"identify\", main=\"Gráfico de influencia\", sub=\"El tamaño del círculo es proporcional a la D_Cook\")\n```\n\nEn total 29 observaciones superan el umbral especificado para la distancia de Cook, pero esto no significa que todas sean influyentes (alto leverage). Particularmente hay 3 observaciones que son marcadas como influyentes significativamente según la distancia de Cook. Esto indica que la inclusión de estas observaciones en el modelo pueden tener una influencia significativa en los coeficientes del modelo y en la predicción de la talla. Se debe explorar con cautela estas observaciones y decidir qué hacer con ellas.\n\nPara esto, se puede comprobar el cambio en los coeficientes del modelo al excluir estas observaciones influyentes.\n\n```{r}\nreg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})\nsummary(reg2)\n```\n\nLas estimaciones de los coeficientes del modelo sin las obervaciones influyentes han cambiado un poco respecto al modelo original. El $R^2$ ajustado ha incrementado un poco también.\n\n### Modelo Lasso\n\nEn este modelo se incluirán las cuatro mediciones, con el fin de escoger la mejor. Se espera que el modelo sea capaz de inducir escacez en los coeficientes del modelo, especialmente a los correspondientes a las mediciones LRT_A, LRT_CM, LRM_90 y LRM_R, de tal manera que pueda escoger la medición que al momento de estimar la talla sea más precisa.\n\nSe particionan los datos en entrenamiento y prueba,\n\n```{r}\nx <- model.matrix(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]\ny <- datos$Talla\n\ngrid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE\n\nset.seed(123)\ntrain <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento\ntest <- (-train) # 10% para prueba\ny.test <- y[test]\n```\n\nAlgunos coeficientes se hacen cero:\n  \n```{r}\nlasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)\nplot(lasso.mod)\n```\n\nSe hace ***k-fold cross validation*** con $k = 10$ y se promedia el MSE:\n  \n```{r}\nset.seed(123)\ncv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda\nplot(cv.out)\nbestlam <- cv.out$lambda.min\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba \n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:12, ]\n```\n\nLos coeficientes del modelo resultante son:\n  \n```{r}\nlasso.coef\n```\n\ny los coeficientes distintos de cero:\n  \n```{r}\nlasso.coef[lasso.coef != 0]\n```\n\nSe observa que algunos coeficientes se hicieron cero, incluyendo el de LRM_90. Pero aún así el modelo todavía incluye LRT_A, LRT_CM y LRM_R al tiempo. Esto puede ser debido a que cada una de las mediciones está muy correlacionada con la talla y que además están muy correlacionadas entre ellas. Se observa que LRT_A tiene un coeficiente mucho mayor que LRT_CM y LRM_R haciendo ver que el modelo las trató de llevar a cero pero no por completo.\n\nEl MSE de este modelo sobre los datos de prueba fue de $8.92$. Se puede probar aumentar el valor de $\\lambda$ (sumando pequeñas cantidades al $\\lambda$ que minimizó el MSE en la validación cruzada), resultará un modelo más sencillo a la vez que aumenta el MSE sobre los datos de prueba.\n\n### Lasso sin tener en cuenta LRT_A\n\nYa que la idea es estimar la altura de los adultos mayores usando alguno de los métodos más sencillos y accecibles para quienes toman las medidas, se excluye en este modelo LRT_A ya que es de difícil acceso y poco económico.\n\nSe ajusta el modelo Lasso con las tres mediciones LRT_CM, LRM_90 y LRM_R.\n\n```{r}\nx <- model.matrix(Talla ~ LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]\ny <- datos$Talla\n\ngrid <- 10^seq(10, -2, length = 100)\n\nset.seed(123)\ntrain <- sample(1:nrow(x), nrow(x)*0.9)\ntest <- (-train)\ny.test <- y[test]\n\nlasso.mod <- glmnet(x[train, ], y[train], alpha = 1, lambda = grid)\n# plot(lasso.mod)\n\nset.seed(123)\ncv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10)\nplot(cv.out)\nbestlam <- cv.out$lambda.min\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2)\n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:11, ]\n\nlasso.coef\n\nlasso.coef[lasso.coef != 0]\n```\n\nEl modelo sugiere incluir al tiempo LRT_CM y LRM_R. Para este modelo el MSE sobre el conjunto de test fue de $10.30$. \n\nSe ajusta el valor de $\\lambda$ con el fin de llevar a cero algunos coeficientes adicionales:\n  \n```{r}\nbestlam <- cv.out$lambda.min + 0.1\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2)\n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:11, ]\n\nlasso.coef\n\nlasso.coef[lasso.coef != 0]\n```\n\nSe obtiene un modelo más sencillo con un MSE de $10.37$.\n\n### Modelo Gamma\n\n```{r}\n\n\n\n# StepCriterion\n\n#sc <- stepCriterion(gamma.reg, direction=\"backward\", criterion=\"aic\", test=\"wald\")\n\n# Ajuste con stepAIC, guardando resultados intermedios\n\n# Forward\ngamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)\n\ngamma.reg <- glm(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Etnia + Peso + Sexo + Programa, family= Gamma(),data = datos)\nsummary(gamma.reg)\n\nstepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction=\"forward\") # k= log(nrow(datos)) - BIC\n\nmodelos_intermedios <- list()\n\n# Función para guardar modelos en cada paso\nguardar_modelos <- function(object, ...) {\n  modelos_intermedios[[length(modelos_intermedios) + 1]] <<- object\n  FALSE  # Devuelve FALSE para continuar con el proceso\n}\n\n# Selección hacia adelante con BIC y almacenamiento de modelos intermedios\nstepwise <- stepAIC(\n  gamma.reg_null,\n  scope = list(lower = gamma.reg_null, upper = gamma.reg),\n  direction = \"forward\",\n  trace = TRUE,\n  k = log(nrow(datos)),  # Usar BIC en lugar de AIC\n  keep = guardar_modelos  # Guardar cada modelo intermedio\n)\n\n\nforms_gamma <- lapply(modelos_intermedios, formula)\n#forms_gamma\n\n\n#kfolds\nbest.fit <- pred <- CV.ERRORS <- cv.errors <- NULL\n\nk = 10\nfor (j in 1:k) {\n  best.fit <- lapply(forms_gamma, function(formula){\n    glm(formula, family = Gamma(), data = datos[folds != j, ])\n})\n  #for (i in 1:length(forms_gamma)) {\n    pred <- lapply(best.fit, function(model){\n      predict(model, datos[folds == j, ], type = \"response\")\n      })\n    cv.errors <- lapply(pred, function(coefs){\n       mean((datos$Talla[folds == j] - coefs)^2)\n    })\n    cv.errors <- as.data.frame(cv.errors)\n    colnames(cv.errors) <- c(paste(\"Mod\", 1:length(forms_gamma)))\n    CV.ERRORS <- rbind(CV.ERRORS, cv.errors)\n  #}\n}\n\n# Error cuadratico medio\nmean.cv.errors <- apply(CV.ERRORS , 2, mean, na.rm = TRUE)\nmean.cv.errors \n\n\n```\n\n","srcMarkdownNoYaml":"\n\n```{r}\n# Librerias \nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(nortest)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(GGally) # para la funcion ggpairs\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(moments)\nlibrary(leaps)\nlibrary(MASS)\nlibrary(lmtest)\nlibrary(car)\nlibrary(BSDA) # Test del signo\nlibrary(glmnet)\nlibrary(glmtoolbox)\nlibrary(MASS)\n```\n\n## Lectura de datos\n \nSe muestra a continuación la forma que tienen los datos.  \n \n```{r}\n# Lectura base de datos\ndatos <- read_excel(\"Datos/Corregida - COMPILADO DATOS COMUNIDAD DE CUIDADO Y CENTRO DÍA.xlsx\", \n                      range = \"B2:AN561\", col_types = c(\"date\", \n                      \"skip\", \"text\", \"text\", \"text\", \"skip\", \n                      \"text\", \"numeric\", \"text\", \"skip\", \n                      \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\", \n                      \"skip\", \"skip\", \"skip\", \"skip\", \"numeric\"))\ncolnames(datos) <- c(\"Fecha\", \"Localidad\", \"Programa\", \"Unidad_atencion\", \n                     \"Sexo\", \"Edad\", \"Etnia\", \"Peso\", \"Talla\",\n                     \"LRT_CM\",\"LRT_A\", \"LRM_90\",\"LRM_R\")\ndatos$Sexo <- as.factor(datos$Sexo)\ndatos$Etnia <- as.factor(datos$Etnia)\ndatos <- datos[-which(datos$Edad<60),] # >60\ndatos <- datos |> as.data.frame()\nhead(datos) |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\n## Análisis descriptivo\n\n### Distribución, atípicos y test de normalidad\n\n#### Sexo\n\n```{r}\n#| layout-ncol: 2\n\n# summary(datos$Sexo)\n# summary(datos$Sexo)/length(datos$Sexo)\n\ndatos_resumen <- datos %>%\n  dplyr::count(Sexo) %>%\n  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3))\ndatos_resumen |> gt() |> gtExtras::gt_theme_538()\n\nggplot(datos_resumen, aes(x = \"\", y = porcentaje, fill = Sexo)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +  # Elimina fondo y ejes\n  labs(title = \"Porcentaje de Hombres y Mujeres\", fill = \"Sexo\") +\n  geom_text(aes(label = paste0(round(porcentaje, 1), \"%\")),\n            position = position_stack(vjust = 0.5), color = \"white\")\n```\n\nLa muestra cuenta con 284 personas de sexo femenino y 275 masculino\n\n#### Edad\n\nResumen de la variable `Edad`:\n\n```{r}\nsummary(datos$Edad)\n```\n\nDistribución de la variable `Edad`\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Edad, freq=FALSE, main = 'Hstograma de Edad', xlab = 'Edad', ylab = 'Densidad')\nlines(density(datos$Edad), col =\"red\")\nbox_Edad <- boxplot(datos$Edad)\n```\n\nDatos atípicos en la variable `Edad`:\n\n```{r}\ndatos[which(datos$Edad>box_Edad$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> \n  tab_options(table.font.size = 9)\n```\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Edad) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Edad, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Edad) # No se tiene normalidad en la edad según el test de lillie\n```\n\nEl mínimo de edad en la muestra es `r summary(datos$Edad)[1]` años, el máximo son `r max(datos$Edad)` años, la media es `r mean(datos$Edad)` años y la mediana es de`median(datos$Edad)` años. Existen dos datos atípicos: 93 y 95 años. \nNo hay evidencia estadística de que la edad siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 4.496e-09, y el test Lilliefors muestra un p-valor de 1.168e-09. \n\n\n#### Etnia\n\nResumen de la variable `Etnia`:\n\n```{r}\ndatos %>%\n  dplyr::count(Etnia) %>%\n  dplyr::mutate(porcentaje = round(n / sum(n) * 100, digits=3)) |> \n  gt() |> gtExtras::gt_theme_538()\n# No se debería incluír un factor tan sesgado en el modelo\n# Se puede tener en cuenta, sin embargo\n```\n\n\n#### Peso\n\nResumen de la variable `Peso`:\n\n```{r}\nsummary(datos$Peso)\n```\n\nDistribución de la variable `Peso`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Peso, freq = FALSE, main = 'Histograma del peso', xlab = 'Peso', ylab = 'Densidad')\nlines(density(datos$Peso), col = \"red\")\nbox_peso <- boxplot(datos$Peso)\n```\n\nTenemos los siguientes datos atípicos en la variable `Peso`:\n\n```{r}\ndatos[which(datos$Peso>box_peso$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `Peso` distinguiendo por `Sexo`:\n\n```{r}\nbox_peso_fm <- boxplot(datos$Peso ~ datos$Sexo, xlab = 'Sexo', ylab = 'Peso')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$Peso>box_peso_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$Peso>box_peso_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 8)\n```\n:::\n\nEn resúmen el mínimo de peso en la muestra es 34.20 kg, el máximo son 101.8 kg, la media son 63.34 kg y la mediana 62.8 kg. En la muestra junta, tenemos $8$ datos atípicos $101.80, 98.70, 97.65, 97.40, 97.10, 95.60, 95.10$ y $94.20$.  Cuando se separa por Sexo, tenemos $2$ datos atípicos en Femenino (97.10 y 91.6), y $4$ en Masculino (101.80, 98.70, 97.65 y 97.40). \n\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Peso) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Peso) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que el peso siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 7.563e-05 y el test Lilliefors muestra un p-valor de 0.047304. \n\n#### Talla\n\nResumen de la variable `Talla`:\n\n```{r}\nsummary(datos$Talla)\n```\n\nDistribución de la variable `Talla`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$Talla, freq = FALSE, main = 'Histograma de Talla', xlab= 'Talla', ylab = 'Densidad')\nlines(density(datos$Talla), col = \"red\")\nbox_talla <- boxplot(datos$Talla)\n```\n\nTenemos un dato atípico en la variable `Talla`:\n\n```{r}\ndatos[which(datos$Talla<box_talla$stats[1]|datos$Talla>box_talla$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistinguiendo por `Sexo`:\n\n```{r}\nbox_talla_fm <- boxplot(datos$Talla ~ datos$Sexo, xlab='Sexo', ylab='Talla')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$Talla<box_talla_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$Talla>box_talla_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nEn hombres: \n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$Talla<box_talla_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$Talla>box_talla_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEn resúmen, el mínimo de talla en la muestra es 127.1 cm, el máximo son 181.5 cm, la media son 155.95 cm y la mediana 155.15 cm. En la muestra junta, tenemos un dato atípico (127.1). Cuando se separa por Sexo, hay tres datos atípicos en Femenino (133.00, 133.85, 127.10, 129.25 y 132.55, 133.90) y en Masculino dos (142.00 y 141.50). \n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$Talla) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$Talla) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nEl test Shapiro-Wilk arrojó un p-valor 0.05641 sugiriendo normalidad pero sin ser muy significativo, mientras que el test Lilliefors muestra un p-valor de 0.04836, por lo que no habría normalidad.\n\n\n\n#### Longitud Rodilla Talón con cinta métrica `LRT_CM`\n\nResumen de la variable `LRT_CM`:\n\n```{r}\nsummary(datos$LRT_CM)\n```\n\nDistribución de la variable `LRT_CM`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRT_CM, freq = FALSE, main = 'Histograma de LRT medido con cinta métrica', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRT_CM), col = \"red\")\nbox_LRT_CM <- boxplot(datos$LRT_CM)\n```\n\nDatos atípicos:\n\n```{r}\ndatos[which(datos$LRT_CM<box_LRT_CM$stats[1]|datos$LRT_CM>box_LRT_CM$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRT_CM` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRT_CM_fm <- boxplot(datos$LRT_CM ~ datos$Sexo, xlab='Sexo', ylab='Longitud en cm')\n```\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRT_CM<box_LRT_CM_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRT_CM>box_LRT_CM_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRT_CM<box_LRT_CM_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRT_CM>box_LRT_CM_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nPruebas de Normalidad:\n\nEn resúmen, el mínimo de LRT con cinta métrica en la muestra es 38 cm, el máximo son 59 cm, la media son 49 cm y la mediana 48.65 cm. En la muestra junta, parece haber tres datos atípicos (59, 39 y 38), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (39 y 38) y uno en Masculino (59). \n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRT_CM) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que la LRT con cinta métrica siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.02391, y el test Lilliefors muestra un p-valor de 0.01056.\n\n#### Longitud Rodilla Talón con Antropómetro `LRT_A`: \n\nResumen de la variable `LRT_A`:\n\n```{r}\nsummary(datos$LRT_A)\n```\n\nDistribución de la variable `LRT_A`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRT_A, freq = FALSE, main ='Histograma de LRT con antropómetro', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRT_A), col = \"red\")\nbox_LRT_A <- boxplot(datos$LRT_A)\n```\n\nDatos atípicos en la variable `LRT_A`:\n\n```{r}\ndatos[which(datos$LRT_A<box_LRT_A$stats[1]|datos$LRT_A>box_LRT_A$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRT_A` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRT_A_fm <- boxplot(datos$LRT_A ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRT con antropómetro en cm')\n```\n\n\nDatos atípicos cuando se distingue por `Sexo` en mujeres:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRT_A<box_LRT_A_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRT_A>box_LRT_A_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos cuando se distingue por `Sexo` en hombres:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRT_A<box_LRT_A_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRT_A>box_LRT_A_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEn resúmen, el mínimo de LRT con antropómetro en la muestra es 36.85 cm, el máximo son 58.35 cm, la media son 47.54 cm y la mediana 47.4 cm. En la muestra junta, tenemos 3 datos atípicos (58.35, 37.00 y 36.85). Cuando se separa por Sexo, parece haber tres datos atípicos en Femenino (37.00, 36.85 y 38.20) y en Masculino dos (57.65 y 58.35).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRT_A) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nNo hay evidencia estadística de que la LRT con antropómetro siga una distribución normal ya que el test Shapiro-Wilk arrojó un p-valor 0.0507 (no es muy significativo), y el test Lilliefors muestra un p-valor de 0.01345. \n\n#### Longitud Rodilla-Maléolo a 90° `LRM_90`\n\nResumen de la variable `LRM_90`:\n\n```{r}\nsummary(datos$LRM_90)\n```\n\nDistribución de la variable `LRM_90`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRM_90, freq = FALSE, main = 'Histograma de LRM a 90°', xlab = 'Longitud en cm', ylab = 'Densidad')\nlines(density(datos$LRM_90), col = \"red\")\nbox_LRM_90<- boxplot(datos$LRM_90)\n```\n\nDatos atípicos en la variable `LRM_90`:\n\n```{r}\ndatos[which(datos$LRM_90<box_LRM_90$stats[1]|datos$LRM_90>box_LRM_90$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRM_90` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRM_90_fm <- boxplot(datos$LRM_90 ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM a 90° en cm')\n```\n\n\nDatos atípicos en mujeres cuando se distingue por `Sexo`:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRM_90<box_LRM_90_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRM_90>box_LRM_90_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos en hombres cuando se distingue por `Sexo`:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRM_90<box_LRM_90_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRM_90>box_LRM_90_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEl mínimo de LRM con la pierna a 90° en la muestra es 31.85 cm, el máximo son 54.65 cm, la media son 43.33 cm y la mediana 43.2 cm. En la muestra junta, tenemos 6 datos atípicos (53.00, 54.65, 52.30, 52.30, 34.00, 31.85). Cuando se separa por Sexo, tenemos 2 datos atípicos en Femenino (34.00 y 31.85), y en Masculino 2 (53.00, 54.65).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRM_90) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nCon el test Shapiro-Wilk no tenemos normalidad en distribución pues tenemos un p-valor de 0.01393, mientras que el test Lilliefors muestra un p-valor de 0.001307, por lo que no habría normalidad.\n\n#### Longitud Rodilla-Maléolo la pierna totalmente estirada `LRM_R`\n\nResumen de la variable `LRM_R`:\n\n```{r}\nsummary(datos$LRM_R)\n```\n\nDistribución de la variable `LRM_R`:\n\n```{r}\n#| layout-ncol: 2\nhist(datos$LRM_R, freq = FALSE, main = 'Histograma de LRM recta', xlab = 'Longitud en cm', ylab='Densidad')\nlines(density(datos$LRM_R), col = \"red\")\nbox_LRM_R<- boxplot(datos$LRM_R)\n```\n\nDatos atípicos en la variable `LRM_R`:\n\n```{r}\ndatos[which(datos$LRM_R<box_LRM_R$stats[1]|datos$LRM_R>box_LRM_R$stats[5]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDistribución de la variable `LRM_R` distinguiendo por `Sexo`:\n\n```{r}\nbox_LRM_R_fm <- boxplot(datos$LRM_R ~ datos$Sexo, xlab = 'Sexo', ylab = 'LRM recta en cm')\n```\n\n\nDatos atípicos en mujeres cuando se distingue por `Sexo`:\n\n::: {layout-nrow=\"2\"}\n\n```{r}\n(datos |> filter(Sexo == \"Femenino\"))[which((datos |> filter(Sexo == \"Femenino\"))$LRM_R<box_LRM_R_fm$stats[1,1]|(datos |> filter(Sexo == \"Femenino\"))$LRM_R>box_LRM_R_fm$stats[5,1]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n\nDatos atípicos en hombres cuando se distingue por `Sexo`:\n\n```{r}\n(datos |> filter(Sexo == \"Masculino\"))[which((datos |> filter(Sexo == \"Masculino\"))$LRM_R<box_LRM_R_fm$stats[1,2]|(datos |> filter(Sexo == \"Masculino\"))$LRM_R>box_LRM_R_fm$stats[5,2]),-c(1,2)] |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)\n```\n:::\n\nEl mínimo de LRM con la pierna recta en la muestra es 31.45 cm, el máximo son 52.5 cm, la media son 42.54 cm y la mediana 42.50 cm. En la muestra junta, parece haber un dato atípico (31.45), cuando se separa por Sexo, parece haber dos datos atípicos en Femenino (33.50 y 31.45), y en Masculino cuatro (52.50, 51.35, 52.50, 51.25, 37.70 y 37.75).\n\nPruebas de Normalidad:\n\n```{r}\n#| layout-ncol: 2\nshapiro.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n# ks.test(datos$Peso, pnorm) # No se tiene normalidad en la edad según el test de Kolmogorov-Smirnov\nlillie.test(datos$LRM_R) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nCon el test Shapiro-Wilk parece haber normalidad pues tenemos un p-valor de 0.09192, mientras que el test Lilliefors muestra un p-valor de 0.004743, por lo que no habría normalidad.\n\n### Análisis de correlación\n\n```{r}\nggpairs(\n  datos[,-c(1:5, 7)],  # Tu subconjunto de datos\n  lower = list(continuous = wrap(\"smooth\", method = \"lm\", color = \"lightblue\")),  # Línea de regresión en rojo\n  title = \"Matriz de correlaciones\"\n)\n```\n\nExiste una fuerte correlación lineal positiva entre la variable talla y cada una de las mediciones de la longitud rodilla-talón y rodilla-maléolo, considerarlas para los diferentes modelos de regresión parece ser una buena opción. La talla está correlacionada con el peso de forma moderada, por lo que valdría la pena explorar su contribución en los modelos propuestos. No parece haber una correlación lineal significativa entre la talla y la edad, sugiriendo que no sería necesario incluir la edad en los modelos propuestos.\n\nEn principio, dado que la relación entre cada una de las medidas de la longitud rodilla-talón y rodilla-maléolo presentan una relación lineal fuerte con la talla, se podría pensar que la que tenga una mayor correlación con la talla, es la que daría mejores estimaciones de la talla real. En este caso, la longitud rodilla-talón con antropómetro, es la que presenta una mayor correlación con la talla, por lo que posiblemente sea más preciso usar esta medida para estimar la talla real de los adultos mayores. Como sabemos, el antropómetro es una herramienta que no siempre es de fácil acceso y justamente queremos evaluar si existen diferencias significativas entre usar esta medición y las demás mediciones que sí son de fácil acceso y aplicación.\n\nEn ese orden de ideas, después de la longitud de rodilla talón con antropómetro, la longitud rodilla-talón con cinta métrica es la variable que tiene más correlación con la talla, luego sigue la longitud rodilla-maléolo con la pierna totalmente estirada y por último la longitud rodilla-maléolo con la pierna a 90 grados.\n\n## Hipótesis\n\n### Longitud rodilla-talón\n\nInicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:\n\n```{r}\n# Comparar LRT CM y A\nboxplot(data.frame(datos$LRT_CM, datos$LRT_A))\n```\n\nSegún el gráfico de cajas (boxplot), parece que hay una pequeña diferencia entre las mediciones de la longitud desde la rodilla hasta el talón realizadas con cinta métrica y con antropómetro. Sin embargo, para estar seguros, es necesario hacer una prueba estadística más formal. Para esto, se calculan las diferencias entre las mediciones de ambos métodos y se verifica si esas diferencias siguen una distribución normal. Dependiendo del resultado, se elegirá la prueba estadística adecuada para comprobar si realmente no hay una diferencia significativa entre ambos tipos de medición.\n\n```{r}\n# Diferencias CM y A\nLRT_dif <- datos$LRT_CM - datos$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro sigan una distribución normal. Por lo tanto, es necesario usar un tipo de prueba estadística diferente, que no dependa de suposiciones sobre la distribución de los datos, para analizar las diferencias en los promedios.\n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\n## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)\n\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\n\nAl principio, se pensó en usar la prueba de Wilcoxon, que es una prueba estadística no paramétrica para evaluar el promedio de las diferencias. Sin embargo, esta prueba asume que las diferencias entre las mediciones son simétricas, pero eso no ocurrió en nuestros datos, ya que el coeficiente de asimetría fue de -0.785, lo que muestra que las diferencias no son simétricas. Por eso, se decidió usar una prueba diferente llamada \"prueba del signo para muestras pareadas\", que no necesita asumir normalidad ni simetría. Aunque esta prueba no da información sobre el promedio de las diferencias, sí permite evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro.\n\n#### Análisis por separado\n\n##### Por sexo\n###### Masculino:\n\n```{r}\n# Diferencias CM y A\nhombres <- datos[datos$Sexo == \"Masculino\",]\nLRT_dif <- hombres$LRT_CM - hombres$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de sexo masculino sigan una distribución normal. \n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.69. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores de sexo masculino.\n\n###### Femenino:\n```{r}\n# Diferencias CM y A\nmujeres <- datos[datos$Sexo == \"Femenino\",]\nLRT_dif <- mujeres$LRT_CM - mujeres$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en las mujeres mayores sigan una distribución normal. \n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en las mujeres mayores.\n\n##### Por programa\n\n###### Centro día:\n```{r}\n# Diferencias CM y A\ncd <- datos[datos$Programa == \"Centro Día Casa de la Sabiduría\",]\nLRT_dif <- cd$LRT_CM - cd$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores del centro día sigan una distribución normal. \n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores del centro día.\n\n###### Comunidad de cuidado\n```{r}\n# Diferencias CM y A\ncc <- datos[datos$Programa == \"Comunidad de Cuidado\",]\nLRT_dif <- cc$LRT_CM - cc$LRT_A\n\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores de las comunidades de cuidado sigan una distribución normal. \n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se aplica Wilcoxon \n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -1.64. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro,  en los adultos mayores de las comunidades de cuidado.\n\n##### Por etnia\n\n###### Blanco-Mestizo\n```{r}\n# Diferencias CM y A \nbm <- datos[datos$Etnia==\"Blanco-Mestizo\",]\nLRT_dif <- bm$LRT_CM - bm$LRT_A\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\nLos resultados de dos pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostraron un valor menor a 0.05. Esto significa que, con un nivel de confianza del 95%, no podemos decir que las diferencias entre las mediciones de rodilla-talón tomadas con una cinta métrica y con un antropómetro en los adultos mayores Blancos-Mestizos sigan una distribución normal. \n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que no hay simetria, entonces no se aplica Wilcoxon \n```\n\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nAl principio, se pensó en usar la prueba de Wilcoxon, pero las diferencias entre las mediciones no son simétricas ya que el coeficiente de asimetría fue de -0.78. Por eso, se decidió usar la prueba del signo para muestras pareadas para evaluar la mediana de las diferencias.\n\nEl resultado de la prueba del signo mostró un p-valor de $2.2 \\times 10^{-16}$, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores Blancos-Mestizos.\n\n###### Afrocolombiano, indigenas, Rrom \n\n```{r}\n# Diferencias CM y A \nnobm <- datos[datos$Etnia!=\"Blanco-Mestizo\",]\nLRT_dif <- nobm$LRT_CM - nobm$LRT_A\n#length(LRT_dif)\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRT_dif)\nboxplot(LRT_dif) # No hay outliers\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRT_dif) # Se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRT_dif) # Se tiene normalidad según el test de Lilliefors\n```\nUno de los resultados de las pruebas estadísticas, Shapiro-Wilk y Lilliefors, mostró un valor menor a 0.05 y la otra un valor mayor. Dado que de estas etnias solo hay 12 adultos mayores, las pruebas son más sensibles y pueden dar resultados menos confiables. Por esa razón, se va a evaluar la simetría de las diferencias para no realizar la prueba que asume normalidad.\n\n```{r}\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRT_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))\np_value # parece que hay simetria, entonces se aplica Wilcoxon \n\n```\nProbrando la simetría de las diferencias, se obtuvo un valor p mayor que 0.05, por lo que no hay suficiente evidencia para rechazar la hipótesis de simetría, lo que sugiere que la distribución de las diferencias es lo suficientemente simétrica como para aplicar una prueba no paramétrica como Wilcoxon.\n\n```{r}\n\nwilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\nEl resultado de la prueba de Wilcoxon mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Sin embargo, la prueba no puede calcular el p-valor exacto debido a la presencia de valores repetidos en las diferencias, por lo que se va a realizar el test del signo.\n```{r}\n# Prueba del signo para muestras pareadas\nSIGN.test(LRT_dif, md = 0, alternative = \"two.sided\")\n```\nEl resultado de la prueba del signo mostró un p-valor menor a 0.5, lo que indica que hay suficiente evidencia estadística para rechazar la idea de que la mediana de las diferencias es igual a cero. Esto significa que las mediciones de la longitud rodilla-talón hechas con la cinta métrica no son equivalentes a las obtenidas con el antropómetro, en los adultos mayores afrocolombiano, indigenas o Rrom.\n\n\n### Longitud rodilla-maléolo\n\nInicialmente se hace una comparación gráfica de ambas técnicas a través de un box-plot:\n\n```{r}\n# Comparar LRM 90 y R\nboxplot(data.frame(datos$LRM_90, datos$LRM_R))\n```\n\nSegún el boxplot, se puede observar que sí existe una leve diferencia entre las distribuciones de las mediciones de la longitud rodilla maléolo con la pierna a 90° y con la pierna completamente estirada. Sin embargo, es necesario, realizar una prueba estadística formal para concluir algo, por lo que se calculan las diferencias entre ambos métodos y se les aplica un test de normalidad para elegir qué prueba utilizar para evaluar la hipótesis nula de que la medición longitud rodilla-maléolo con la pierna completamente estirada es igual a la medición de la longitud rodilla-maléolo con la pierna a $90°$.\n\n```{r}\n# Diferencias CM y A\nLRM_dif <- datos$LRM_90 - datos$LRM_R\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(LRM_dif)\nboxplot(LRM_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(LRM_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(LRM_dif) # No se tiene normalidad en la edad según el test de Lilliefors\n```\n\nDado que en ambos test, Shapiro-Wilk y Lilliefors, se obtuvo un p-valor menor a $0.05$, entonces, con una significancia del $5\\%$, no hay evidencia estadística de que las diferencias entre las mediciones rodilla-talón con cinta métrica y con antropómetro sigan una distribució normal. Por lo tanto, se hace necesario realizar un test no paramétrico para media de las diferencias.\n\n```{r}\n#| eval: false\n#| echo: false\n# Test Wilcoxon\n\n## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos\n\nasimetria <- moments::skewness(LRM_dif)\n\nt_test <- asimetria / sqrt(6 / length(LRM_dif))  # Estadístico t\np_value <- 2 * (1 - pt(abs(t_test), df = length(LRM_dif) - 1))\np_value # parece que no hay simetria, entonces no se puede aplicar Wilcoxon \n\n# wilcox.test(LRT_dif, mu = 0, alternative = \"two.sided\") # usando las diferencias\n# wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = \"two.sided\", paired = TRUE) # usando directamente los datos\n```\n\n```{r}\n# Prueba del signo para muestras pareadas\n## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)\n\nSIGN.test(LRM_dif, md = 0, alternative = \"two.sided\")\n```\n\nNuevamente, se consideró aplicar la prueba de Wilcoxon para evaluar la media de las diferencias, pero esta prueba no se aplicó ya que el coeficiente de asimetría obtenido fue de $2.022$. Este valor indica una falta de simetría en las diferencias de las mediciones. Por esta razón, de nuevo se optó por utilizar la prueba del signo para muestras pareadas.\n\nEl resultado de la prueba del signo arrojó un p-valor de $2.2 \\times 10^{-16}$, indicando evidencia estadística suficiente para rechazar la hipótesis nula de que la mediana de las diferencias es igual a cero. Por lo tanto, se concluye que las mediciones de la longitud rodilla-maléolo realizadas con la pierna completamente estirada no son equivalentes a las obtenidas con la pierna a $90°$.\n\n### Talla real y estimación Benjumea (LRT) con cinta métrica\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con cinta métrica. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es \"Rrom\", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$benjumea_cm <- ifelse(\n  datos$Sexo == \"Masculino\" & datos$Etnia == \"Blanco-Mestizo\",\n  75.514 + 1.883 * datos$LRT_CM - 0.108 * datos$Edad,\n  ifelse(\n    datos$Sexo == \"Femenino\" & datos$Etnia == \"Blanco-Mestizo\",\n    86.497 + 1.553 * datos$LRT_CM - 0.119 * datos$Edad,\n    ifelse(\n      datos$Sexo == \"Masculino\" & datos$Etnia == \"Indigena\",\n      82.695 + 1.745 * datos$LRT_CM - 0.121 * datos$Edad,\n      ifelse(\n        datos$Sexo == \"Femenino\" & datos$Etnia == \"Indigena\",\n        90.281 + 1.436 * datos$LRT_CM - 0.102 * datos$Edad,\n        ifelse(\n          datos$Sexo == \"Masculino\" & datos$Etnia == \"Afrocolombiano\",\n          79.298 + 1.855 * datos$LRT_CM - 0.141 * datos$Edad,\n          ifelse(\n            datos$Sexo == \"Femenino\" & datos$Etnia == \"Afrocolombiano\",\n            76.233 + 1.767 * datos$LRT_CM - 0.098 * datos$Edad,\n            NA # solo hay un NA que es el Rrom\n          )\n        )\n      )\n    )\n  )\n)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con cinta métrica y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$benjumea_cm))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con cinta métrica, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$benjumea_cm\ntalla_dif <- talla_dif[!is.na(talla_dif)]\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \\times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con cinta métrica no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Benjumea sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$benjumea_cm)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Benjumea (LRT) con antropómetro\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Benjumea que tienen en cuenta las variables Sexo, Edad, Etnia y longitud rodilla-talón con antropómetro. Hay que tener en cuenta que en la muestra hay un individuo cuya Etnia es \"Rrom\", para este individuo no existe una fórmula de Benjumea para estimar su talla, por lo que no se tuvo en cuenta para la evaluación de la hipótesis de que la media de la diferencia entre la estimación de la talla por medio de las fórmulas de Benjumea y la talla real es cero.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$benjumea_a <- ifelse(\n  datos$Sexo == \"Masculino\" & datos$Etnia == \"Blanco-Mestizo\",\n  75.514 + 1.883 * datos$LRT_A - 0.108 * datos$Edad,\n  ifelse(\n    datos$Sexo == \"Femenino\" & datos$Etnia == \"Blanco-Mestizo\",\n    86.497 + 1.553 * datos$LRT_A - 0.119 * datos$Edad,\n    ifelse(\n      datos$Sexo == \"Masculino\" & datos$Etnia == \"Indigena\",\n      82.695 + 1.745 * datos$LRT_A - 0.121 * datos$Edad,\n      ifelse(\n        datos$Sexo == \"Femenino\" & datos$Etnia == \"Indigena\",\n        90.281 + 1.436 * datos$LRT_A - 0.102 * datos$Edad,\n        ifelse(\n          datos$Sexo == \"Masculino\" & datos$Etnia == \"Afrocolombiano\",\n          79.298 + 1.855 * datos$LRT_A - 0.141 * datos$Edad,\n          ifelse(\n            datos$Sexo == \"Femenino\" & datos$Etnia == \"Afrocolombiano\",\n            76.233 + 1.767 * datos$LRT_A - 0.098 * datos$Edad,\n            NA # solo hay un NA que es el Rrom\n          )\n        )\n      )\n    )\n  )\n)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Benjumea con antropómetro y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$benjumea_a))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Benjumea con antropómetro, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$benjumea_a\ntalla_dif <- talla_dif[!is.na(talla_dif)]\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $4.103 \\times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Benjumea con antropómetro no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Benjumea sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$benjumea_a)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Arango Zamor (LRM) a $90°$\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo a $90°$.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$arango_90 <- ifelse(\n  datos$Sexo == \"Masculino\",\n  119.6 + 1.121*datos$LRM_90 - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_90 - 0.159*datos$Edad)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$ y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$arango_90))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a $90°$, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$arango_90\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $9.685 \\times 10^{-12}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna a $90°$ no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$arango_90)^2, na.rm = TRUE)\n```\n\n#### Sin los outliers\n\n```{r}\nbox_talla_dif <- boxplot(talla_dif) # hay muchos outliers\noutliers <- box_talla_dif$out\n\ntalla_dif1 <- talla_dif[!(talla_dif %in% outliers)]\n\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif1)\nboxplot(talla_dif1) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif1)\n\n# Prueba t para muestras pareadas\nt.test(talla_dif1, alternative = \"two.sided\", mu = 0)\n```\n\nTambién da que la diferencia no es cero.\n\n### Talla real y estimación Arango Zamor (LRM) con la pierna estirada\n\nPrimero se realiza el cálculo de la estimación de la talla utilizando las fórmulas de Arango y Zamora que tienen en cuenta las variables Sexo, Edad y longitud rodilla-maléolo con la pierna estirada.\n\n```{r}\n# Estimaciones de la talla utilizando las fórmulas de Benjumea\ndatos$arango_r <- ifelse(\n  datos$Sexo == \"Masculino\",\n  119.6 + 1.121*datos$LRM_R - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_R - 0.159*datos$Edad)\n```\n\nComo antes, se hizo un análisis visual a través de un box-plot, donde se observa que aparentemente no hay una diferencia entre la estimación de la talla con las fórmulas de Arango y Zamora con la pierna estirada y la talla real. Sin embargo, es necesario realizar una prueba estadística formal para concluir.\n\n```{r}\n# Comparar benjumea y talla real\nboxplot(data.frame(datos$Talla, datos$arango_r))\n```\n\nSe calculan las diferencias entre la talla real y la estimación de la talla con las fórmulas de Arango y Zamora con la pierna a estirada, luego, a estas diferencias se les aplica el test de Sahpiro-Wilk para normalidad y el test Lilliefors de normalidad, esto para decidir qué test utilizar para evaluar la media de las diferencias.\n\n```{r}\n# Diferencias benjumea y talla real\ntalla_dif <- datos$Talla - datos$arango_r\n\n# Como se ve graficamente, parece que no hay normalidad\nhist(talla_dif)\nboxplot(talla_dif) # hay muchos outliers\n\n# Pruebas de normalidad\n## Test Shapiro-Wilk\nshapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks\n\n## Test lilliefors\nlillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors\n```\n\nEn ambos test, se obtiene un p-valor mayor a $0.05$, por lo que se afirma, que con una significancia del $5\\%$, existe evidencia estadística de que las diferencias siguen una distribución normal, por lo tanto, para evaluar la media de las diferencias, se puede implementar una prueba $t$ para muestras pareadas.\n\n```{r}\n# t.test(datos$Talla, datos$benjumea, alternative = \"two.sided\", mu = 0, paired = TRUE, na.action = na.omit)\n\nt.test(talla_dif, alternative = \"two.sided\", mu = 0)\n```\n\nLuego de aplicar la prueba $t$, con una significancia del $5\\%$, existe evidencia estadística para rechazar la hipótesis nula ya que el p-valor es $2.2 \\times 10^{-16}$, por lo tanto, se concluye que la media de las diferencias entre la talla real y la estimación con las fórmulas de Arango y Zamora con la pierna estirada no es cero, luego, parece que las estimaciones no son cercanas a la talla real.\n\nEl MSE del modelo de Arango y Zamora sobre nuestros datos es el siguiente:\n\n```{r}\nmean((datos$Talla - datos$arango_r)^2, na.rm = TRUE)\n```\n\n## Modelos\n\nA continuación el resumen de la evaluación de las hipótesis de interés:\n\n-   La diferencia en las mediciones de LRT con antropómetro y con cinta métrica resultó ser estadísticamente significativa.\n-   La diferencia en las mediciones de LRM con la pierna a $90°$ y la pierna estirada resultó ser estadísticamente significativa.\n\nEstos resultados sigieren que:\n\n-   No es posible determinar que las mediciones de LRT con la cinta métrica sean iguales a las obtenidad con antropómetro. Asumiendo que la medición con antropómetro es más exacta, las mediciones con la cinta métrica suelen sobreestimar en promedio a las del antropómetro.\n-   Tampoco es posible determinar que las mediciones de LRM con la pierna a $90°$ y con la pierna estirada sean iguales. La medición con la pierna estirada suele ser en promedio menor a la medición hecha con la pierna a $90°$.\n\nLos resultados obtenidos al evaluar las fórmulas de ***Benjumea*** y de ***Arango y Zamora*** en mustra de adultos mayores que atiende la SDIS, parecen no tener muy buenos resultados a la hora de estimar la talla de los adultos mayores.\n\nDado estos resultados, se concluye que se requiere de fórmulas específicas para la población que atiende la **SDIS**. Además, se deberá ajustar estos modelos para las cuatro mediciones pues la evaluación de las hipótesis no dieron indicios de la igualdad entre los métodos de las mediciones.\n\n### Selección del mejor modelo usando LRT_A\n\nInicialmente, se hará la selección del mejor modelo para LRT_A mediante un enfoque predictivo.\n\nA continuación se hace una búsqueda del mejor modelo por cada número de posibles combinaciones de variables. Primero se hará la búsqueda usando todo el conjunto de datos.\n\n```{r}\nregfit.full <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa,\n                          datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables \n\n(reg.summary <- summary(regfit.full))\n# names(reg.summary)\n```\n\n$R^2$, $R^2$ ajustado, SCE, y BIC para cada mejor modelo del correspondiente tamaño:\n\n```{r}\nreg.summary$rsq\nreg.summary$adjr2\nreg.summary$rss\nreg.summary$bic\n```\n\nUsando el criterio BIC, el mejor modelo es el de 3 variables:\n\n```{r}\nwhich.min(reg.summary$bic)\nplot(reg.summary$bic , xlab = \"Number of Variables\",\nylab = \"BIC\", type = \"l\")\npoints(3, reg.summary$bic[3], col = \"red\", cex = 2,\npch = 20)\nplot(regfit.full , scale = \"bic\")\n```\n\nUsando el $R^2$ ajustado, se sugiere un modelo con 5 variables:\n\n```{r}\nplot(regfit.full , scale = \"adjr2\")\n```\n\nLos coeficientes del mejor modelo usando el criterio de BIC son:\n\n```{r}\ncoef(regfit.full, 3)\n```\n\nEsto sugiere usar el modelo $Talla = 58.67 + 2.19 LRT\\_A - 0.12Edad + 3.06Sexo$,\\\n$$Sexo = \\begin{cases} 1 & \\text{si sexo = hombre} \\\\ 0 & \\text{si sexo = mujer} \\end{cases}$$\n\nAhora se hará la búsqueda del mejor modelo usando ***K - fold cross validation*** con el fin de calcular directamente los errores de predicción sobre los datos de testeo y evitar así el sobreajuste.\n\n-   Se crean ***K - folds*** (pliegues) de aproximadamente igual tamaño. En este caso fijamos $k = 10$. Como tenemos $558$ datos, cada pliegue será de tamaño 55 o 56.\n-   El $k-ésimo$ pliegue servirá para testear, y los demás pliegues se juntan para entrenar los modelos. Osea que se usará un $90\\%$ de los datos para entrenamiento y $10\\%$ para test.\n-   Para $k = 1,\\cdots,10,$ se hace la búsqueda del mejor modelo para cada número de variables y se calcula el MSE.\n-   Luego, se promedia el MSE a través de los $10$ pliegues y se escoge el tamaño de modelo con menor MSE promedio.\n-   Finalmente, se hace la búsqueda del mejor modelo por cada número de variables usando todos los datos disponibles y se escoge el modelo asociado al tamaño del modelo obtenido en la validación cruzada.\n\nTamaño de los pliegues:\n\n```{r}\nk <- 10 # k-folds\nn <- nrow(datos)\nset.seed(123)\nfolds <- sample(rep(1:k, length = n))\ntable(folds) # tamaño de cada k-fold\ncv.errors <- matrix(NA, k, 7, dimnames = list(NULL , paste (1:7))) # Matriz para almacenar los errores\n```\n\nMSE promedio a través de los $10$ pliegues para cada número de variables incluídas en el modelo:\n\n```{r}\n# Función para hacer la predicción de los datos de test en cada k-fold\npredict.regsubsets <- function(object , newdata , id, ...) {\n  form <- as.formula(object$call [[2]])\n  mat <- model.matrix(form , newdata)\n  coefi <- coef(object , id = id)\n  xvars <- names(coefi)\n  mat[, xvars] %*% coefi\n}\n\nfor (j in 1:k) {\n  best.fit <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos[folds != j, ], nvmax = 10)\n  for (i in 1:7) { # Se usa 8 porque los modelos tienen un tamaño máximo de 8 variables en el regsubsets\n  pred <- predict(best.fit , datos[folds == j, ], id = i)\n  cv.errors[j, i] <- mean((datos$Talla[folds == j] - pred)^2)\n  }\n}\n# Hay un pequeño problema de multicolinealidad (parece que sucede cuando se incluye la etnia)\n# por eso en vez del 8 puse 7 (porque generaba un error por multicolinealidad)\n\nmean.cv.errors <- apply(cv.errors , 2, mean, na.rm = TRUE)\nmean.cv.errors # El menor MSE promedio es cuando se usa un modelo con 3 variables\n```\n\nEl MSE se minimiza usando un modelo de 3 variables:\n\n```{r}\npar(mfrow = c(1, 1))\nplot(mean.cv.errors , type = \"b\")\n```\n\nSe busca nuevamente el mejor modelo de tres variables usando todos los datos:\n\n```{r}\n# Se busca nuevamente el mejor modelo de 3 variables\nreg.best <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos, nvmax = 10)\nregbest.summary <- summary(reg.best)\nregbest.summary$bic\n\ncoef(reg.best, 3)\n```\n\nCasualmente volvió a dar el mismo modelo con tres variables que incluye LRT_A, la Edad y el Sexo. Esto es seguramente porque las demás variables no contribuyen significativamente a la presición predictiva de los modelos.\n\nAhora se validarán los supuestos para el mejor modelo obtenido:\n\n```{r}\nreg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)\n(summary.reg <- summary(reg))\n```\n\nEl modelo tiene un $R^2$ ajustado de $0.8861$, es decir que aproximadamente un $88.61\\%$ de la variabilidad de la talla es explicada por LRT_A, la edad y el sexo. \n\n***Linealidad:*** Con el fin de verificar que la relación entre la talla y las variables LRT_A (discriminando por sexo) y la edad es lineal, se visualiza el gráfico de los residuos vs los valores predichos del modelo $\\left(\\hat{e},\\hat{y} \\right)$:\n\n```{r}\nplot(reg, which = 1)\n```\n\nEl gráfico no muestra ningún patrón marcado, la ubicación de los puntos parece ser aleatoria alrededor de cero, indicando también homoscedasticidad en los residuales y posible independencia de los mismos. El gráfico muestra algunos valores atípicos que valdría la pena explorar.\n\n***Independencia de los errores:*** Aunque nuestros datos no son temporales, el test de Durbin-Watson nos puede ayudar a evaluar la autocorrelación de los errores del modelo:\n\n```{r}\ndwtest(reg)\n```\n\nLa estadística del test de Durbin-Watson es muy cercano a $2$, se concluye que los errores son independientes.\n\n***Normalidad de los errores:*** Se realiza el gráfico QQ-plot para comparar la distribución de los residuales del modelo con la distribución teórica de una normal. También se hace el test de normalidad de Lilliefors y Anderson-Darling:\n\n```{r}\nplot(reg, which = 2)\nlillie.test(reg$residuals)\nad.test(reg$residuals)\n```\n\nEl QQ-plot muestra que los residuales se ajustan aceptablemente a una distribución normal. Las pruebas de normalidad de Lilliefors y Anderson-Darling también apoyan este resultado.\n\n***Homoscedasticidad:*** Aunque no se vio un patron que indicara heteroscedasticidad en el gráfico de los residuales vs los valores predichos, a continuación se muestra el gráfico de los residuales estandarizados vs los valores predichos con el fin de mejorar la interpretabilidad de la homoscedasticidad y tener una visión más clara de las observaciones atípicas e influyentes:\n\n```{r}\nplot(reg, which = 3)\n```\n\nNo se observan patrones que indiquen hereroscedasticidad en los residuos (forma de cono o embudo). Se siguien observando algunas observaciones atípicas y/o influyentes.\n\nAdicional, se realiza la prueba de Breusch-Pagan para verificar la homoscedasticidad de los residuales:\n\n```{r}\nbptest(reg)\n```\n\nNo se rechaza la hipótesis nula de que los errores del modelo son homoscedasticos.\n\n***Multicolinealidad:*** Se verifica que las variables incluídas en el modelo no están altamente correlacionadas entre sí, y así evitar obtener resultados inestables que dificulten la interpretabilidad de los coeficientes del modelo. Se calculan los Factores de Inflación de la Varianza (VIFs):\n\n```{r}\nvif(reg)\n```\n\nDado que los VIFs son mucho menores a 5, esto indica que cada variable tiene una correlación moderada (leve) con las demás. Por lo que se puede concluir que los resultados del modelo posiblemente no estarán muy afectados por la multicolinealidad.\n\n***El modelo está bien especificado:*** Se hace el test de RESET para examinar si el modelo ajustado está bien especificado o si se han omitido términos no lineales o interacciones importantes:\n\n```{r}\nresettest(reg, type=\"regressor\")\nresettest(reg, type=\"fitted\")\n```\n\nNo se rechaza la hipótesis nula de que el modelo está bien especificado.\n\n***Obervaciones atípicas y de alto apalancamiento:*** \n\n```{r}\n#| layout-ncol: 2\nplot(reg,which=5)\nstud_res<-studres(reg)\n# head(sort(abs(stud_res),decreasing=TRUE))\nboxplot(stud_res)\n```\n\nUsando los residuales estudentizados, se observan $5$ datos atípicos.\n\n```{r}\n#| layout-ncol: 2\ncorte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica\nplot(reg, which=4, cook.levels=corte)\nabline(h=corte, lty=2, col=\"red\")\ncooksd<-cooks.distance(reg)\n# cooksd[which(cooksd>corte)]\n\ninfluencePlot(reg, id.method=\"identify\", main=\"Gráfico de influencia\", sub=\"El tamaño del círculo es proporcional a la D_Cook\")\n```\n\nEn total 29 observaciones superan el umbral especificado para la distancia de Cook, pero esto no significa que todas sean influyentes (alto leverage). Particularmente hay 3 observaciones que son marcadas como influyentes significativamente según la distancia de Cook. Esto indica que la inclusión de estas observaciones en el modelo pueden tener una influencia significativa en los coeficientes del modelo y en la predicción de la talla. Se debe explorar con cautela estas observaciones y decidir qué hacer con ellas.\n\nPara esto, se puede comprobar el cambio en los coeficientes del modelo al excluir estas observaciones influyentes.\n\n```{r}\nreg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})\nsummary(reg2)\n```\n\nLas estimaciones de los coeficientes del modelo sin las obervaciones influyentes han cambiado un poco respecto al modelo original. El $R^2$ ajustado ha incrementado un poco también.\n\n### Modelo Lasso\n\nEn este modelo se incluirán las cuatro mediciones, con el fin de escoger la mejor. Se espera que el modelo sea capaz de inducir escacez en los coeficientes del modelo, especialmente a los correspondientes a las mediciones LRT_A, LRT_CM, LRM_90 y LRM_R, de tal manera que pueda escoger la medición que al momento de estimar la talla sea más precisa.\n\nSe particionan los datos en entrenamiento y prueba,\n\n```{r}\nx <- model.matrix(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]\ny <- datos$Talla\n\ngrid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE\n\nset.seed(123)\ntrain <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento\ntest <- (-train) # 10% para prueba\ny.test <- y[test]\n```\n\nAlgunos coeficientes se hacen cero:\n  \n```{r}\nlasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)\nplot(lasso.mod)\n```\n\nSe hace ***k-fold cross validation*** con $k = 10$ y se promedia el MSE:\n  \n```{r}\nset.seed(123)\ncv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda\nplot(cv.out)\nbestlam <- cv.out$lambda.min\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba \n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:12, ]\n```\n\nLos coeficientes del modelo resultante son:\n  \n```{r}\nlasso.coef\n```\n\ny los coeficientes distintos de cero:\n  \n```{r}\nlasso.coef[lasso.coef != 0]\n```\n\nSe observa que algunos coeficientes se hicieron cero, incluyendo el de LRM_90. Pero aún así el modelo todavía incluye LRT_A, LRT_CM y LRM_R al tiempo. Esto puede ser debido a que cada una de las mediciones está muy correlacionada con la talla y que además están muy correlacionadas entre ellas. Se observa que LRT_A tiene un coeficiente mucho mayor que LRT_CM y LRM_R haciendo ver que el modelo las trató de llevar a cero pero no por completo.\n\nEl MSE de este modelo sobre los datos de prueba fue de $8.92$. Se puede probar aumentar el valor de $\\lambda$ (sumando pequeñas cantidades al $\\lambda$ que minimizó el MSE en la validación cruzada), resultará un modelo más sencillo a la vez que aumenta el MSE sobre los datos de prueba.\n\n### Lasso sin tener en cuenta LRT_A\n\nYa que la idea es estimar la altura de los adultos mayores usando alguno de los métodos más sencillos y accecibles para quienes toman las medidas, se excluye en este modelo LRT_A ya que es de difícil acceso y poco económico.\n\nSe ajusta el modelo Lasso con las tres mediciones LRT_CM, LRM_90 y LRM_R.\n\n```{r}\nx <- model.matrix(Talla ~ LRT_CM + LRM_90 + LRM_R + Edad + Peso + Sexo + Etnia + Programa, data = datos)[, -1]\ny <- datos$Talla\n\ngrid <- 10^seq(10, -2, length = 100)\n\nset.seed(123)\ntrain <- sample(1:nrow(x), nrow(x)*0.9)\ntest <- (-train)\ny.test <- y[test]\n\nlasso.mod <- glmnet(x[train, ], y[train], alpha = 1, lambda = grid)\n# plot(lasso.mod)\n\nset.seed(123)\ncv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10)\nplot(cv.out)\nbestlam <- cv.out$lambda.min\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2)\n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:11, ]\n\nlasso.coef\n\nlasso.coef[lasso.coef != 0]\n```\n\nEl modelo sugiere incluir al tiempo LRT_CM y LRM_R. Para este modelo el MSE sobre el conjunto de test fue de $10.30$. \n\nSe ajusta el valor de $\\lambda$ con el fin de llevar a cero algunos coeficientes adicionales:\n  \n```{r}\nbestlam <- cv.out$lambda.min + 0.1\nlasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])\nmean((lasso.pred - y.test)^2)\n\nout <- glmnet(x, y, alpha = 1, lambda = grid)\nlasso.coef <- predict(out , type = \"coefficients\", s = bestlam)[1:11, ]\n\nlasso.coef\n\nlasso.coef[lasso.coef != 0]\n```\n\nSe obtiene un modelo más sencillo con un MSE de $10.37$.\n\n### Modelo Gamma\n\n```{r}\n\n\n\n# StepCriterion\n\n#sc <- stepCriterion(gamma.reg, direction=\"backward\", criterion=\"aic\", test=\"wald\")\n\n# Ajuste con stepAIC, guardando resultados intermedios\n\n# Forward\ngamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)\n\ngamma.reg <- glm(Talla ~ LRT_A + LRT_CM + LRM_90 + LRM_R + Edad + Etnia + Peso + Sexo + Programa, family= Gamma(),data = datos)\nsummary(gamma.reg)\n\nstepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction=\"forward\") # k= log(nrow(datos)) - BIC\n\nmodelos_intermedios <- list()\n\n# Función para guardar modelos en cada paso\nguardar_modelos <- function(object, ...) {\n  modelos_intermedios[[length(modelos_intermedios) + 1]] <<- object\n  FALSE  # Devuelve FALSE para continuar con el proceso\n}\n\n# Selección hacia adelante con BIC y almacenamiento de modelos intermedios\nstepwise <- stepAIC(\n  gamma.reg_null,\n  scope = list(lower = gamma.reg_null, upper = gamma.reg),\n  direction = \"forward\",\n  trace = TRUE,\n  k = log(nrow(datos)),  # Usar BIC en lugar de AIC\n  keep = guardar_modelos  # Guardar cada modelo intermedio\n)\n\n\nforms_gamma <- lapply(modelos_intermedios, formula)\n#forms_gamma\n\n\n#kfolds\nbest.fit <- pred <- CV.ERRORS <- cv.errors <- NULL\n\nk = 10\nfor (j in 1:k) {\n  best.fit <- lapply(forms_gamma, function(formula){\n    glm(formula, family = Gamma(), data = datos[folds != j, ])\n})\n  #for (i in 1:length(forms_gamma)) {\n    pred <- lapply(best.fit, function(model){\n      predict(model, datos[folds == j, ], type = \"response\")\n      })\n    cv.errors <- lapply(pred, function(coefs){\n       mean((datos$Talla[folds == j] - coefs)^2)\n    })\n    cv.errors <- as.data.frame(cv.errors)\n    colnames(cv.errors) <- c(paste(\"Mod\", 1:length(forms_gamma)))\n    CV.ERRORS <- rbind(CV.ERRORS, cv.errors)\n  #}\n}\n\n# Error cuadratico medio\nmean.cv.errors <- apply(CV.ERRORS , 2, mean, na.rm = TRUE)\nmean.cv.errors \n\n\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"CodigoQMD.html"},"language":{"toc-title-document":"Tabla de contenido","toc-title-website":"Tabla de contenido","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"Bibliografia","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Institución","title-block-affiliation-plural":"Affiliations","title-block-published":"Fecha de Publicación","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Editar este libro","repo-action-links-source":"View source","repo-action-links-issue":"Reportar un error","back-to-top":"Volver arriba","search-no-results-text":"Ninguna coincidencia","search-matching-documents-text":"coincidencias","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Activar modo oscuro","toggle-reader-mode":"Activar modo lectura","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figura","crossref-tbl-title":"Tabla","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","title":"Caso 1 de Consultoría: Comparación de la talla estimada mediante ecuaciones de predicción en adultos mayores.","author":[{"name":"Ana Sofia Bello, Karol Ayala, Carlos Mario Castaño, Jesus Zisa","affiliation":"Departamento de estadística - Universidad Nacional de Colombia."}],"address":["Departamento de estadística - Universidad Nacional de Colombia."],"code-summary":"","editor_options":{"chunk_output_type":"console"},"grid":{"body-width":"1100px","sidebar-width":"400px","margin-width":"100px","gutter-width":"1em"},"toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}