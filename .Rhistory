reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_R + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_R", MSE = mean(errores))) # No se incluye pq aparentemente hay una leve homocedasticidad en los errores
regfit.full <- regsubsets(Talla ~ LRM_90 + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRM_90 + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRM_90", MSE = mean(errores))) # No se incluye pq el modelo no está bien especificado
MSEs <- MSEs |> as.data.frame()
MSEs |> gt() |> gtExtras::gt_theme_538() |> tab_options(table.font.size = 9)
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
x <- model.matrix(Talla ~ LRM_R + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_R", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
x <- model.matrix(Talla ~ LRM_90 + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_90", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_A + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRT_A + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRT_A", MSE = mean(errores)))
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_CM + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRT_CM", MSE = mean(errores)))
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRT_CM", MSE = mean(errores)))
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRM_R + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRM_R + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRM_R", MSE = mean(errores)))
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRM_90 + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRM_90 + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Error cuadratico medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Gamma", Medida = "LRM_90", MSE = mean(errores)))
MSEs
table(datos$Etnia)
datos$Benjumea = NULL
datos
View(datos)
datos$Benjumea = rep(NA,nrow(datos))
ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena",
datos$Benjumea = 82.695 + 1.745*datos$LRT_A - 0.121*datos$Edad, datos$Benjumea)
datos$Benjumea = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRT_A - 0.121*datos$Edad, datos$Benjumea)
# LRT_A
datos$Benjumea_LRT_A = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRT_A - 0.121*datos$Edad, datos$Benjumea_LRT_A)
# Indigena femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRT_A - 0.102*datos$Edad, datos$Benjumea_LRT_A)
# Afrodescendiente masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRT_A - 0.141*datos$Edad, datos$Benjumea_LRT_A)
# Afrodescendiente femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRT_A - 0.098*datos$Edad, datos$Benjumea_LRT_A)
# Blanco-Mestizo masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRT_A - 0.108*datos$Edad, datos$Benjumea_LRT_A)
# Blanco-Mestizo femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRT_A - 0.119*datos$Edad, datos$Benjumea_LRT_A)
sum(is.na(datos$Benjumea_LRT_A))
?mean
mean((datos$Talla - datos$Benjumea_LRT_A)^2, na.rm = TRUE)
# LRT_CM
datos$Benjumea_LRT_CM = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRT_CM - 0.121*datos$Edad, datos$Benjumea_LRT_CM)
# Indigena femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRT_CM - 0.102*datos$Edad, datos$Benjumea_LRT_CM)
# Afrodescendiente masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRT_CM - 0.141*datos$Edad, datos$Benjumea_LRT_CM)
# Afrodescendiente femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRT_CM - 0.098*datos$Edad, datos$Benjumea_LRT_CM)
# Blanco-Mestizo masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRT_CM - 0.108*datos$Edad, datos$Benjumea_LRT_CM)
# Blanco-Mestizo femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRT_CM - 0.119*datos$Edad, datos$Benjumea_LRT_CM)
sum(is.na(datos$Benjumea_LRT_CM)) # falta para Rrom
mean((datos$Talla - datos$Benjumea_LRT_CM)^2, na.rm = TRUE)
# LRM_R
datos$Benjumea_LRM_R = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRM_R = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRM_R - 0.121*datos$Edad, datos$Benjumea_LRM_R)
# Indigena femenino
datos$Benjumea_LRM_R = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRM_R - 0.102*datos$Edad, datos$Benjumea_LRM_R)
# Afrodescendiente masculino
datos$Benjumea_LRM_R = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRM_R - 0.141*datos$Edad, datos$Benjumea_LRM_R)
# Afrodescendiente femenino
datos$Benjumea_LRM_R = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRM_R - 0.098*datos$Edad, datos$Benjumea_LRM_R)
# Blanco-Mestizo masculino
datos$Benjumea_LRM_R = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRM_R - 0.108*datos$Edad, datos$Benjumea_LRM_R)
# Blanco-Mestizo femenino
datos$Benjumea_LRM_R = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRM_R - 0.119*datos$Edad, datos$Benjumea_LRM_R)
mean((datos$Talla - datos$Benjumea_LRM_R)^2, na.rm = TRUE)
# LRT_CM
datos$Benjumea_LRT_CM = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRT_CM - 0.121*datos$Edad, datos$Benjumea_LRT_CM)
# Indigena femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRT_CM - 0.102*datos$Edad, datos$Benjumea_LRT_CM)
# Afrodescendiente masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRT_CM - 0.141*datos$Edad, datos$Benjumea_LRT_CM)
# Afrodescendiente femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRT_CM - 0.098*datos$Edad, datos$Benjumea_LRT_CM)
# Blanco-Mestizo masculino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRT_CM - 0.108*datos$Edad, datos$Benjumea_LRT_CM)
# Blanco-Mestizo femenino
datos$Benjumea_LRT_CM = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRT_CM - 0.119*datos$Edad, datos$Benjumea_LRT_CM)
mean((datos$Talla - datos$Benjumea_LRT_CM)^2, na.rm = TRUE)
# LRT_A
datos$Benjumea_LRT_A = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRT_A - 0.121*datos$Edad, datos$Benjumea_LRT_A)
# Indigena femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRT_A - 0.102*datos$Edad, datos$Benjumea_LRT_A)
# Afrodescendiente masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRT_A - 0.141*datos$Edad, datos$Benjumea_LRT_A)
# Afrodescendiente femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRT_A - 0.098*datos$Edad, datos$Benjumea_LRT_A)
# Blanco-Mestizo masculino
datos$Benjumea_LRT_A = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRT_A - 0.108*datos$Edad, datos$Benjumea_LRT_A)
# Blanco-Mestizo femenino
datos$Benjumea_LRT_A = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRT_A - 0.119*datos$Edad, datos$Benjumea_LRT_A)
sum(is.na(datos$Benjumea_LRT_A)) # falta para Rrom
mean((datos$Talla - datos$Benjumea_LRT_A)^2, na.rm = TRUE)
summary(datos$Benjumea_LRM_R)
mean((datos$Talla - datos$Benjumea_LRM_R)^2, na.rm = TRUE)
# LRM_90
datos$Benjumea_LRM_90 = rep(NA,nrow(datos))
# Indigena masculino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Indigena", 82.695 + 1.745*datos$LRM_90 - 0.121*datos$Edad, datos$Benjumea_LRM_90)
# Indigena femenino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Indigena", 90.281 + 1.436*datos$LRM_90 - 0.102*datos$Edad, datos$Benjumea_LRM_90)
# Afrodescendiente masculino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Afrocolombiano", 79.298 + 1.855*datos$LRM_90 - 0.141*datos$Edad, datos$Benjumea_LRM_90)
# Afrodescendiente femenino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Afrocolombiano", 76.233 + 1.767*datos$LRM_90 - 0.098*datos$Edad, datos$Benjumea_LRM_90)
# Blanco-Mestizo masculino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo=="Masculino" & datos$Etnia == "Blanco-Mestizo", 75.514 + 1.883*datos$LRM_90 - 0.108*datos$Edad, datos$Benjumea_LRM_90)
# Blanco-Mestizo femenino
datos$Benjumea_LRM_90 = ifelse(datos$Sexo!="Masculino" & datos$Etnia == "Blanco-Mestizo", 86.497 + 1.553*datos$LRM_90 - 0.119*datos$Edad, datos$Benjumea_LRM_90)
summary(datos$Benjumea_LRM_90)
mean((datos$Talla - datos$Benjumea_LRM_90)^2, na.rm = TRUE)
diferencias <- datos$Talla - datos$Benjumea_LRM_90
summary(diferencias)
# LRM_R
datos$Arango_LRM_R = rep(NA,nrow(datos))
# Masculino
datos$Arango_LRM_R = ifelse(datos$Sexo=="Masculino", 119.6 + 1.121*datos$LRM_R - 0.117*datos$Edad, datos$Arango_LRM_R)
# Femenino
datos$Arango_LRM_R = ifelse(datos$Sexo!="Masculino", 107.7 + 1.263*datos$LRM_R - 0.159*datos$Edad, datos$Arango_LRM_R)
mean((datos$Talla - datos$Arango_LRM_R)^2, na.rm = TRUE)
```{r}
# LRM_90
datos$Arango_LRM_90 = rep(NA,nrow(datos))
# Masculino
datos$Arango_LRM_90 = ifelse(datos$Sexo=="Masculino", 119.6 + 1.121*datos$LRM_90 - 0.117*datos$Edad, datos$Arango_LRM_90)
# Femenino
datos$Arango_LRM_90 = ifelse(datos$Sexo!="Masculino", 107.7 + 1.263*datos$LRM_90 - 0.159*datos$Edad, datos$Arango_LRM_90)
mean((datos$Talla - datos$Arango_LRM_90)^2, na.rm = TRUE)
MSEs[5:8,]
MSEs[1:4,]
MSEs[9:12,]
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
dwtest(reg)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
plot(reg, which = 3)
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
x <- model.matrix(Talla ~ LRT_A + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_A", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRT_CM + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRT_CM", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRM_R + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_R", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef
lasso.coef[lasso.coef != 0]
x <- model.matrix(Talla ~ LRM_90 + Edad + Sexo + Etnia, data = datos)[, -1]
y <- datos$Talla
grid <- 10^seq(10, -2, length = 100) # grilla para buscar el lambda que minimice el MSE
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*0.9) # 90% entrenamiento
test <- (-train) # 10% para prueba
y.test <- y[test]
lasso.mod <- glmnet(x[train , ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(123)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1, nfolds = 10) # validación cruzada para buscar el lambda
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod , s = bestlam, newx = x[test , ])
mean((lasso.pred - y.test)^2) # MSE sobre los datos de prueba
MSEs <- rbind(MSEs, data.frame(Modelo = "LASSO", Medida = "LRM_90", MSE = mean((lasso.pred - y.test)^2)))
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out , type = "coefficients", s = bestlam)[1:7,]
lasso.coef
lasso.coef[lasso.coef != 0]
MSEs[5:8,]
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_A + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# k folds
best.fit <- pred <- CV.ERRORS <- cv.errors <- NULL
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- glm(Talla ~ LRT_A + Edad + Sexo, family= Gamma(), data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data, type = "response")
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Estimacion del modelo
gamma.final <- glm(Talla ~ LRT_A + Edad + Sexo, family= Gamma(),data = datos)
summary(gamma.final)
$$\ln(Talla) = 1.033e-02 - 8.813e-05 LRT\_A + 4.989e-06 Edad - -1.318e-04 Sexo$$\
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRT_CM + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Estimacion del modelo
gamma.final <- glm(Talla ~ LRT_CM + Edad + Sexo, family= Gamma(),data = datos)
summary(gamma.final)
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRM_R + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Estimacion del modelo
gamma.final <- glm(Talla ~ LRM_R + Edad + Sexo, family= Gamma(),data = datos)
summary(gamma.final)
# Modelo nulo
gamma.reg_null <- glm(Talla ~ 1, family= Gamma(),data = datos)
# Estimacion del modelo
gamma.reg <- glm(Talla ~ LRM_90 + Edad + Etnia + Sexo, family= Gamma(),data = datos)
summary(gamma.reg)
stepwise <- stepAIC(gamma.reg_null, scope = list(lower = gamma.reg_null, upper = gamma.reg), trace = TRUE, k= 2, direction="forward") # k= log(nrow(datos)) - BIC
# Estimacion del modelo
gamma.final <- glm(Talla ~ LRM_90 + Edad + Sexo, family= Gamma(),data = datos)
summary(gamma.final)
