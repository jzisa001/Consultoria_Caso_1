hombres <- datos[datos$Sexo == "Masculino",]
LRT_dif <- hombres$LRT_CM - hombres$LRT_A
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Diferencia de mediciones LRT (hombres)', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
# Diferencias CM y A
mujeres <- datos[datos$Sexo == "Femenino",]
LRT_dif <- mujeres$LRT_CM - mujeres$LRT_A
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Diferencia de mediciones LRT (mujeres)', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Test Wilcoxon
## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos
asimetria <- moments::skewness(LRT_dif)
symmetry.test(LRT_dif)
t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon
wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
# Diferencias CM y A
cd <- datos[datos$Programa == "Centro Día Casa de la Sabiduría",]
LRT_dif <- cd$LRT_CM - cd$LRT_A
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Histograma de las la diferencia de mediciones LRT', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Test Wilcoxon
## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos
asimetria <- moments::skewness(LRT_dif)
t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon
wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
# Diferencias CM y A
cc <- datos[datos$Programa == "Comunidad de Cuidado",]
LRT_dif <- cc$LRT_CM - cc$LRT_A
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Histograma de las la diferencia de mediciones LRT', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
# Diferencias CM y A
bm <- datos[datos$Etnia=="Blanco-Mestizo",]
LRT_dif <- bm$LRT_CM - bm$LRT_A
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Histograma de las la diferencia de mediciones LRT', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
# Diferencias CM y A
nobm <- datos[datos$Etnia!="Blanco-Mestizo",]
LRT_dif <- nobm$LRT_CM - nobm$LRT_A
#length(LRT_dif)
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRT_dif, freq = FALSE, main = 'Histograma de las la diferencia de mediciones LRT', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRT_dif), col = "red")
abline(v = median(LRT_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRT_dif) # No hay outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRT_dif) # Se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRT_dif) # Se tiene normalidad según el test de Lilliefors
# Test Wilcoxon
## Requiere simetria en los datos, por lo que se realiza un test de simetria basado en momentos
asimetria <- moments::skewness(LRT_dif)
t_test <- asimetria / sqrt(6 / length(LRT_dif))  # Estadístico t
p_value <- 2 * (1 - pt(abs(t_test), df = length(LRT_dif) - 1))
p_value # parece que hay simetria, entonces se aplica Wilcoxon
wilcox.test(LRT_dif, mu = 0, alternative = "two.sided") # usando las diferencias
#wilcox.test(datos$LRT_CM, datos$LRT_A, mu = 0, alternative = "two.sided", paired = TRUE) # usando directamente los datos
# Prueba del signo para muestras pareadas
SIGN.test(LRT_dif, md = 0, alternative = "two.sided")
# Comparar LRM 90 y R
boxplot(data.frame(datos$LRM_90, datos$LRM_R), ylab = 'Longitud Rodilla-Maleolo (cm)', xaxt = "n")
axis(1, at = c(1, 2),
labels = c("Pierna a 90°", "Pierna recta"))
# Diferencias CM y A
LRM_dif <- datos$LRM_90 - datos$LRM_R
# Como se ve graficamente, parece que no hay normalidad
par(mfrow=c(1,2))
hist(LRM_dif, freq = FALSE, main = 'Histograma de las la diferencia de mediciones LRT', ylab = 'Densidad', xlab = 'Diferenencia (cm)')
lines(density(LRM_dif), col = "red")
abline(v = median(LRM_dif, na.rm = TRUE), col = "red", lty = 2)
boxplot(LRM_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(LRM_dif) # No se tiene normalidad en la edad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(LRM_dif) # No se tiene normalidad en la edad según el test de Lilliefors
# Prueba del signo para muestras pareadas
## Es menos potente que Wilcoxon pero funciona aunque no haya normalidad ni simetria, permite dar conclusiones sobre la mediana (si no hay simetria)
SIGN.test(LRM_dif, md = 0, alternative = "two.sided")
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$benjumea_cm <- ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Blanco-Mestizo",
75.514 + 1.883 * datos$LRT_CM - 0.108 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Blanco-Mestizo",
86.497 + 1.553 * datos$LRT_CM - 0.119 * datos$Edad,
ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Indigena",
82.695 + 1.745 * datos$LRT_CM - 0.121 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Indigena",
90.281 + 1.436 * datos$LRT_CM - 0.102 * datos$Edad,
ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Afrocolombiano",
79.298 + 1.855 * datos$LRT_CM - 0.141 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Afrocolombiano",
76.233 + 1.767 * datos$LRT_CM - 0.098 * datos$Edad,
NA # solo hay un NA que es el Rrom
)
)
)
)
)
)
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$benjumea_cm))
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$benjumea_cm
talla_dif <- talla_dif[!is.na(talla_dif)]
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)
t.test(talla_dif, alternative = "two.sided", mu = 0)
mean((datos$Talla - datos$benjumea_cm)^2, na.rm = TRUE)
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out
talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif1)
# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$benjumea_a <- ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Blanco-Mestizo",
75.514 + 1.883 * datos$LRT_A - 0.108 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Blanco-Mestizo",
86.497 + 1.553 * datos$LRT_A - 0.119 * datos$Edad,
ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Indigena",
82.695 + 1.745 * datos$LRT_A - 0.121 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Indigena",
90.281 + 1.436 * datos$LRT_A - 0.102 * datos$Edad,
ifelse(
datos$Sexo == "Masculino" & datos$Etnia == "Afrocolombiano",
79.298 + 1.855 * datos$LRT_A - 0.141 * datos$Edad,
ifelse(
datos$Sexo == "Femenino" & datos$Etnia == "Afrocolombiano",
76.233 + 1.767 * datos$LRT_A - 0.098 * datos$Edad,
NA # solo hay un NA que es el Rrom
)
)
)
)
)
)
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$benjumea_a))
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$benjumea_a
talla_dif <- talla_dif[!is.na(talla_dif)]
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)
t.test(talla_dif, alternative = "two.sided", mu = 0)
mean((datos$Talla - datos$benjumea_a)^2, na.rm = TRUE)
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out
talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif1)
# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$arango_90 <- ifelse(
datos$Sexo == "Masculino",
119.6 + 1.121*datos$LRM_90 - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_90 - 0.159*datos$Edad)
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$arango_90))
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$arango_90
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)
t.test(talla_dif, alternative = "two.sided", mu = 0)
mean((datos$Talla - datos$arango_90)^2, na.rm = TRUE)
box_talla_dif <- boxplot(talla_dif) # hay muchos outliers
outliers <- box_talla_dif$out
talla_dif1 <- talla_dif[!(talla_dif %in% outliers)]
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif1)
boxplot(talla_dif1) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif1) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif1)
# Prueba t para muestras pareadas
t.test(talla_dif1, alternative = "two.sided", mu = 0)
# Estimaciones de la talla utilizando las fórmulas de Benjumea
datos$arango_r <- ifelse(
datos$Sexo == "Masculino",
119.6 + 1.121*datos$LRM_R - 0.117*datos$Edad, 107.7 + 1.263*datos$LRM_R - 0.159*datos$Edad)
# Comparar benjumea y talla real
boxplot(data.frame(datos$Talla, datos$arango_r))
# Diferencias benjumea y talla real
talla_dif <- datos$Talla - datos$arango_r
# Como se ve graficamente, parece que no hay normalidad
hist(talla_dif)
boxplot(talla_dif) # hay muchos outliers
# Pruebas de normalidad
## Test Shapiro-Wilk
shapiro.test(talla_dif) # Sí se tiene normalidad según el test de Shapiro-Wilks
## Test lilliefors
lillie.test(talla_dif) # Sí se tiene normalidad según el test de Lilliefors
# t.test(datos$Talla, datos$benjumea, alternative = "two.sided", mu = 0, paired = TRUE, na.action = na.omit)
t.test(talla_dif, alternative = "two.sided", mu = 0)
mean((datos$Talla - datos$arango_r)^2, na.rm = TRUE)
regfit.full <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
plot(regfit.full , scale = "adjr2")
coef(regfit.full, 3)
k <- 10 # k-folds
n <- nrow(datos)
set.seed(123)
folds <- sample(rep(1:k, length = n))
table(folds) # tamaño de cada k-fold
cv.errors <- matrix(NA, k, 7, dimnames = list(NULL , paste (1:7))) # Matriz para almacenar los errores
# Función para hacer la predicción de los datos de test en cada k-fold
predict.regsubsets <- function(object , newdata , id, ...) {
form <- as.formula(object$call [[2]])
mat <- model.matrix(form , newdata)
coefi <- coef(object , id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
for (j in 1:k) {
best.fit <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos[folds != j, ], nvmax = 10)
for (i in 1:7) { # Se usa 8 porque los modelos tienen un tamaño máximo de 8 variables en el regsubsets
pred <- predict(best.fit , datos[folds == j, ], id = i)
cv.errors[j, i] <- mean((datos$Talla[folds == j] - pred)^2)
}
}
# Hay un pequeño problema de multicolinealidad (parece que sucede cuando se incluye la etnia)
# por eso en vez del 8 puse 7 (porque generaba un error por multicolinealidad)
mean.cv.errors <- apply(cv.errors , 2, mean, na.rm = TRUE)
mean.cv.errors # El menor MSE promedio es cuando se usa un modelo con 3 variables
par(mfrow = c(1, 1))
plot(mean.cv.errors , type = "b")
# Se busca nuevamente el mejor modelo de 3 variables
reg.best <- regsubsets(Talla ~ LRT_A + Peso + Edad + Sexo + Etnia + Programa, data = datos, nvmax = 10)
regbest.summary <- summary(reg.best)
regbest.summary$bic
coef(reg.best, 3)
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
dwtest(reg)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
plot(reg, which = 3)
bptest(reg)
vif(reg)
resettest(reg, type="regressor")
resettest(reg, type="fitted")
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
#| layout-ncol: 2
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})
summary(reg2)
regfit.full <- regsubsets(Talla ~ LRT_A + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
# Crear 5 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_A + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Para ir almacenando los MSE de los modelos y las longitudes
MSEs <- data.frame(Modelo = character(),
Medida = character(),
MSE = numeric())
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRT_A", MSE = mean(errores)))
reg <- lm(Talla ~ LRT_A + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
plot(reg, which = 1)
dwtest(reg)
plot(reg, which = 2)
lillie.test(reg$residuals)
ad.test(reg$residuals)
plot(reg, which = 3)
bptest(reg)
vif(reg)
resettest(reg, type="regressor")
resettest(reg, type="fitted")
#| layout-ncol: 2
plot(reg,which=5)
stud_res<-studres(reg)
# head(sort(abs(stud_res),decreasing=TRUE))
boxplot(stud_res)
#| layout-ncol: 2
n <- nrow(datos)
corte <- 4/(n-length(reg$coefficients)-2) #Es una regla usada en la práctica
plot(reg, which=4, cook.levels=corte)
abline(h=corte, lty=2, col="red")
cooksd<-cooks.distance(reg)
# cooksd[which(cooksd>corte)]
influencePlot(reg, id.method="identify", main="Gráfico de influencia", sub="El tamaño del círculo es proporcional a la D_Cook")
reg2 <- update(reg,subset={setdiff(row(datos)[,1], c(533,43,549))})
summary(reg2)
regfit.full <- regsubsets(Talla ~ LRT_CM + Edad + Sexo + Etnia,
datos, nbest = 1, nvmax = 10) # Mejor modelo de cada número de variables
(reg.summary <- summary(regfit.full))
# names(reg.summary)
reg.summary$rsq
reg.summary$adjr2
reg.summary$rss
reg.summary$bic
?regsubsets
summary(regfit.full)
reg.summary$rsq
reg.summary$bic
?regsubs+
?
?regsubsets
summary.regsubsets
summary.regsubsets()
which.min(reg.summary$bic)
plot(reg.summary$bic , xlab = "Number of Variables",
ylab = "BIC", type = "l")
points(3, reg.summary$bic[3], col = "red", cex = 2,
pch = 20)
plot(regfit.full , scale = "bic")
coef(regfit.full, 3)
coef(regfit.full)
coef(regfit.full, 3)
coeficientes <- coef(regfit.full, 3)
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_CM + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
datos
datos
# Crear 10 folds
set.seed(123)  # Semilla para reproducibilidad
folds <- vfold_cv(datos, v = 10)
# Inicializar lista para almacenar errores
errores <- numeric(length(folds$splits))
# Loop para entrenar y validar el modelo en cada fold
for (i in seq_along(folds$splits)) {
# Dividir datos
train_data <- analysis(folds$splits[[i]])  # Datos de entrenamiento
test_data <- assessment(folds$splits[[i]]) # Datos de validación
# Ajustar el modelo
modelo <- lm(Talla ~ LRT_CM + Edad + Sexo, data = train_data)
# Predicciones
predicciones <- predict(modelo, newdata = test_data)
# Calcular error cuadrático medio
errores[i] <- mean((test_data$Talla - predicciones)^2)
}
# Promedio del error cuadrático medio
mean(errores)
MSEs <- rbind(MSEs, data.frame(Modelo = "Normal", Medida = "LRT_CM", MSE = mean(errores)))
MSEs
reg <- lm(Talla ~ LRT_CM + Edad + Sexo, data = datos)
(summary.reg <- summary(reg))
mean(reg$residuals)
mean(reg$residuals)
plot(reg, which = 1)
print("La media de los residuales es cercana a 0: ")
mean(reg$residuals)
plot(reg, which = 1)
